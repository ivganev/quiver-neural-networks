{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "floppy-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affected-christopher",
   "metadata": {},
   "source": [
    "### Example Data\n",
    "\n",
    "Our goal will be to approximate the sigmoid function with a radial neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "central-wages",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1250e6550>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_small = torch.tensor([-4 + i/2 for i in range(17)]).unsqueeze(1)\n",
    "y_small = 3*torch.square(x_small-1) + 2\n",
    "#x_small, y_small\n",
    "plt.scatter(x_small,y_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personal-gateway",
   "metadata": {},
   "source": [
    "### Layer by layer functions\n",
    "\n",
    "Here are the functions in each layer. WARNING: this may need some updating and checking!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "varying-philip",
   "metadata": {},
   "outputs": [],
   "source": [
    "def radial_sigmoid(v): \n",
    "    # There's almost certainly a better way to do this:\n",
    "    norms_v = torch.tensor([torch.linalg.norm(v[i]) for i in range(len(v))]).unsqueeze(1)\n",
    "    return torch.sigmoid(norms_v)*v\n",
    "\n",
    "def radial_ReLU(v): \n",
    "    norms_v = torch.tensor([torch.linalg.norm(v[i]) for i in range(len(v))]).unsqueeze(1)\n",
    "    # The norms are positive, so relu is the identity\n",
    "    return norms_v*v\n",
    "\n",
    "def radial_square(v): \n",
    "    norms_v = torch.tensor([torch.linalg.norm(v[i]) for i in range(len(v))]).unsqueeze(1)\n",
    "    return (norms_v**2)*v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nervous-picture",
   "metadata": {},
   "source": [
    "### Neural Network\n",
    "\n",
    "We define the linear layers with the trainable parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "indonesian-aquatic",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "dim_vector = (1,4,1)\n",
    "\n",
    "first_linear = nn.Linear(dim_vector[0], dim_vector[1]) \n",
    "second_linear = nn.Linear(dim_vector[1], dim_vector[2]) \n",
    "\n",
    "initial_params = chain(first_linear.parameters(), second_linear.parameters())\n",
    "optimizer = optim.SGD(initial_params, lr=1e-3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cognitive-controversy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x_input):\n",
    "    return second_linear(radial_sigmoid(first_linear(x_input)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "israeli-yellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(y_predict, y_train):\n",
    "    squared_diffs = (y_predict - y_train)**2\n",
    "    return squared_diffs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "equivalent-divorce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, model, loss_fn, x_train, y_train):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        y_predict = model(x_train) # <1>\n",
    "        loss_train = loss_fn(y_predict, x_train)\n",
    "\n",
    "        #t_p_val = model(t_u_val) # <1>\n",
    "        #loss_val = loss_fn(t_p_val, t_c_val)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward() # <2>\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch == 1 or epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch}, Training loss {loss_train.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "noticed-placement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training loss 3.5424\n",
      "Epoch 100, Training loss 0.8018\n",
      "Epoch 200, Training loss 0.2234\n",
      "Epoch 300, Training loss 0.0651\n",
      "Epoch 400, Training loss 0.0213\n",
      "Epoch 500, Training loss 0.0094\n",
      "Epoch 600, Training loss 0.0061\n",
      "Epoch 700, Training loss 0.0052\n",
      "Epoch 800, Training loss 0.0050\n",
      "Epoch 900, Training loss 0.0049\n",
      "Epoch 1000, Training loss 0.0049\n",
      "\n",
      "Parameter containing:\n",
      "tensor([[-1.1225],\n",
      "        [ 0.3486],\n",
      "        [ 0.1149],\n",
      "        [ 0.5298]], requires_grad=True) Parameter containing:\n",
      "tensor([[-0.6570,  0.4824,  0.1860,  0.1786]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.4482,  1.0181, -0.6470, -0.6257], requires_grad=True) Parameter containing:\n",
      "tensor([0.0528], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "training_loop(\n",
    "    n_epochs = 1000, \n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    x_train = x_small,\n",
    "    y_train = y_small)\n",
    "\n",
    "print()\n",
    "print(first_linear.weight, second_linear.weight)\n",
    "print(first_linear.bias, second_linear.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solar-uncle",
   "metadata": {},
   "source": [
    "### Try to appoximate any function on a given range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "sticky-argument",
   "metadata": {},
   "outputs": [],
   "source": [
    "def approximate(f, lower, upper, n_hidden, n_epochs):\n",
    "    x_train = torch.tensor([lower + i/5 for i in range(int(upper-lower)*5 + 1)])\n",
    "    y_train = torch.tensor([f(x_train[i]) for i in range(len(x_train))])\n",
    "    x_train = x_train.unsqueeze(1)\n",
    "    y_train = y_train.unsqueeze(1)\n",
    "    \n",
    "    first_linear = nn.Linear(1, n_hidden) \n",
    "    second_linear = nn.Linear(n_hidden, 1) \n",
    "\n",
    "    initial_params = chain(first_linear.parameters(), second_linear.parameters())\n",
    "    optimizer = optim.SGD(initial_params, lr=1e-3) \n",
    "    \n",
    "    def model(x_input):\n",
    "        return second_linear(radial_sigmoid(first_linear(x_input)))\n",
    "    \n",
    "    def loss_fn(y_predict, y_train):\n",
    "        squared_diffs = (y_predict - y_train)**2\n",
    "        return squared_diffs.mean()\n",
    "    \n",
    "    training_loop(\n",
    "        n_epochs = n_epochs, \n",
    "        optimizer = optimizer,\n",
    "        model = model,\n",
    "        loss_fn = loss_fn,\n",
    "        x_train = x_train,\n",
    "        y_train = y_train)\n",
    "    \n",
    "    print(first_linear.weight, second_linear.weight)\n",
    "    print(first_linear.bias, second_linear.bias)\n",
    "    \n",
    "    return lambda x: second_linear(radial_sigmoid(first_linear(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "incoming-newton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training loss 10.8482\n",
      "Epoch 100, Training loss 0.7402\n",
      "Epoch 200, Training loss 0.0350\n",
      "Epoch 300, Training loss 0.0160\n",
      "Epoch 400, Training loss 0.0109\n",
      "Epoch 500, Training loss 0.0091\n",
      "Epoch 600, Training loss 0.0083\n",
      "Epoch 700, Training loss 0.0081\n",
      "Epoch 800, Training loss 0.0079\n",
      "Epoch 900, Training loss 0.0079\n",
      "Epoch 1000, Training loss 0.0079\n",
      "Parameter containing:\n",
      "tensor([[-0.8337],\n",
      "        [ 0.4023],\n",
      "        [-0.8352],\n",
      "        [ 0.3054]], requires_grad=True) Parameter containing:\n",
      "tensor([[-0.3354,  0.2966, -0.6453,  0.2940]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.5670,  0.6912, -0.1582,  0.9125], requires_grad=True) Parameter containing:\n",
      "tensor([-0.7322], requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.approximate.<locals>.<lambda>(x)>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "approximate(lambda x: x**2 - 3*x + 5, -5, 3, 4, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "acquired-frederick",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training loss 12.9897\n",
      "Epoch 100, Training loss 0.0242\n",
      "Epoch 200, Training loss 0.0114\n",
      "Epoch 300, Training loss 0.0086\n",
      "Epoch 400, Training loss 0.0075\n",
      "Epoch 500, Training loss 0.0071\n",
      "Epoch 600, Training loss 0.0069\n",
      "Epoch 700, Training loss 0.0069\n",
      "Epoch 800, Training loss 0.0069\n",
      "Epoch 900, Training loss 0.0068\n",
      "Epoch 1000, Training loss 0.0068\n",
      "Parameter containing:\n",
      "tensor([[ 0.4623],\n",
      "        [ 0.9862],\n",
      "        [-0.5348],\n",
      "        [-0.6418]], requires_grad=True) Parameter containing:\n",
      "tensor([[-0.0300,  0.8569,  0.0060, -0.2878]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.4706, 0.1195, 0.7306, 0.0651], requires_grad=True) Parameter containing:\n",
      "tensor([-0.0666], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "model_trained = approximate(lambda x: 5*int(-3 < x < -1.5) or (2<x<4), -5, 5, 4, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "governmental-asbestos",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5.051633358001709\n",
      "-4.847899436950684\n",
      "-4.643871784210205\n",
      "-4.439484119415283\n",
      "-4.234655857086182\n",
      "-4.029296398162842\n",
      "-3.823296546936035\n",
      "-3.6165354251861572\n",
      "-3.4088785648345947\n",
      "-3.2001841068267822\n",
      "-2.9903104305267334\n",
      "-2.7791309356689453\n",
      "-2.566556692123413\n",
      "-2.352571725845337\n",
      "-2.1372790336608887\n",
      "-1.9209729433059692\n",
      "-1.7042180299758911\n",
      "-1.4879529476165771\n",
      "-1.2735909223556519\n",
      "-1.063098430633545\n",
      "-0.8589963912963867\n",
      "-0.6642138957977295\n",
      "-0.4816702604293823\n",
      "-0.3134174048900604\n",
      "-0.15915285050868988\n",
      "-0.014358196407556534\n"
     ]
    }
   ],
   "source": [
    "for i in range(26):\n",
    "    print(model_trained(torch.tensor([[-5 + i/5]])).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "worth-democrat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x125eb01f0>]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f_ex = lambda x: 5*int(-9 < x < -7.5) or (3<x<4)\n",
    "x_ex = torch.tensor([-10 + i/10 for i in range(201)])\n",
    "y_ex = torch.tensor([f_ex(x_ex[i]) for i in range(len(x_ex))])\n",
    "#pred_ex = torch.tensor([model_trained(x_ex[i]) for i in range(len(x_ex))])\n",
    "plt.plot(x_ex, y_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limiting-information",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "paperback-probe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "settled-belize",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-words",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mounted-boundary",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afraid-center",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "northern-worth",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brave-liquid",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inside-knitting",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-edwards",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stainless-wagon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brave-powder",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "placed-drive",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dutch-albuquerque",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blank-storage",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "different-medline",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "backed-directory",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "based-florist",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "established-little",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "separate-franchise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.4613],\n",
       "        [ 1.3392],\n",
       "        [ 1.2148],\n",
       "        [ 1.0872],\n",
       "        [ 0.9557],\n",
       "        [ 0.8204],\n",
       "        [ 0.6836],\n",
       "        [ 0.5518],\n",
       "        [ 0.4357],\n",
       "        [ 0.3440],\n",
       "        [ 0.2644],\n",
       "        [ 0.1753],\n",
       "        [ 0.0717],\n",
       "        [-0.0421],\n",
       "        [-0.1610],\n",
       "        [-0.2815],\n",
       "        [-0.4021]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test that it works\n",
    "model(x_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explicit-reality",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medium-supplier",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bearing-connection",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manual-complex",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transparent-words",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hundred-program",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quality-stewart",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applied-history",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offensive-departure",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "palestinian-synthesis",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defensive-lover",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "smaller-wellington",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.4045],\n",
       "        [-0.4320],\n",
       "        [-0.9632],\n",
       "        [ 0.1473]], requires_grad=True)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_linear.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "tracked-horizontal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.8694, -0.4586,  0.3702, -0.0613], requires_grad=True)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_linear.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "funded-commerce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x12db8e820>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_linear.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "considerable-employee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of Linear(in_features=1, out_features=4, bias=True)>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_linear.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "irish-guest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generator"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(first_linear.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "forward-engineer",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Maybe need https://docs.python.org/3/library/itertools.html#itertools.chain   ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "continued-victoria",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "itertools.chain"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(initial_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "whole-dryer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ranking-norwegian",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Not sure how to deal with the parameters, so am only using the weights from the first linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "institutional-wilderness",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, learning_rate, params, x_train, y_train):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        if params.grad is not None:  # <1>\n",
    "            params.grad.zero_()\n",
    "        \n",
    "        y_predict = model(x_train) \n",
    "        loss = loss_fn(y_predict, y_train)\n",
    "        loss.backward()\n",
    "        \n",
    "        with torch.no_grad():  # <2>\n",
    "            params -= learning_rate * params.grad\n",
    "\n",
    "        if epoch % 500 == 0:\n",
    "            print('Epoch %d, Loss %f' % (epoch, float(loss)))\n",
    "            \n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endangered-tennis",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "We test out the training in the example of the sigmoid function. In order to run this we need to fix the definitions in the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "civilian-lemon",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'itertools.chain' object has no attribute 'grad'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-7ff144a6c6c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m training_loop(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mn_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_small\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-666adb56ec65>\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(n_epochs, learning_rate, params, x_train, y_train)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtraining_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# <1>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'itertools.chain' object has no attribute 'grad'"
     ]
    }
   ],
   "source": [
    "training_loop(\n",
    "    n_epochs = 5000, \n",
    "    learning_rate = 1e-2, \n",
    "    params = initial_params,\n",
    "    x_train = x_small, \n",
    "    y_train = y_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "south-banner",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fantastic-adaptation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mental-postage",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-watershed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "listed-finland",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enabling-wings",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "inappropriate-gasoline",
   "metadata": {},
   "source": [
    "## Another idea:\n",
    "\n",
    "Use a sequence model with two linear layers and insert a radial layer in between"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ranking-magnet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=1, out_features=4, bias=True)\n",
       "  (1): Linear(in_features=4, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_model = nn.Sequential(\n",
    "            nn.Linear(1, 4), # <1>\n",
    "            nn.Linear(4, 1)) # <2>\n",
    "seq_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "painful-hayes",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x12bfd8200>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "corrected-audit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.5605],\n",
       "         [-0.1222],\n",
       "         [ 0.9176],\n",
       "         [ 0.9634]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.4245, -0.3865, -0.1646,  0.5677], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.3056,  0.0092, -0.2019, -0.3926]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.3129], requires_grad=True)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(seq_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "rotary-republic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.8176,  0.1023, -3.8350, -3.2857],\n",
       "        [ 1.5374,  0.0412, -3.3762, -2.8040],\n",
       "        [ 1.2571, -0.0199, -2.9174, -2.3223],\n",
       "        [ 0.9768, -0.0810, -2.4586, -1.8407],\n",
       "        [ 0.6965, -0.1421, -1.9998, -1.3590],\n",
       "        [ 0.4163, -0.2032, -1.5410, -0.8773],\n",
       "        [ 0.1360, -0.2643, -1.0822, -0.3956],\n",
       "        [-0.1443, -0.3254, -0.6234,  0.0861],\n",
       "        [-0.4245, -0.3865, -0.1646,  0.5677],\n",
       "        [-0.7048, -0.4476,  0.2941,  1.0494],\n",
       "        [-0.9851, -0.5087,  0.7529,  1.5311],\n",
       "        [-1.2653, -0.5698,  1.2117,  2.0128],\n",
       "        [-1.5456, -0.6309,  1.6705,  2.4945],\n",
       "        [-1.8259, -0.6920,  2.1293,  2.9761],\n",
       "        [-2.1061, -0.7531,  2.5881,  3.4578],\n",
       "        [-2.3864, -0.8142,  3.0469,  3.9395],\n",
       "        [-2.6667, -0.8753,  3.5057,  4.4212]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_model[0](x_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "boxed-magazine",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x_input):\n",
    "    return seq_model[1](radial_sigmoid(seq_model[0](x_input)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "variable-anxiety",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affiliated-pharmacy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-alliance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "purple-fantasy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "actual-generator",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrong-environment",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capital-plane",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inappropriate-civilization",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seventh-liverpool",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confidential-airport",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standard-theology",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinct-macro",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "unlike-joshua",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_linear = nn.Linear(1, 4) \n",
    "second_linear = nn.Linear(4, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "married-halloween",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graduate-forge",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "partial-graduate",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solar-equity",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greenhouse-player",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behind-peninsula",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immediate-preview",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "japanese-geology",
   "metadata": {},
   "source": [
    "# ___________________________ SCRAPS _______________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "returning-parade",
   "metadata": {},
   "source": [
    "### The rest of this notebook is scraps\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "lightweight-harvey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'first_linear': tensor([[1., 1., 1., 1.]], requires_grad=True),\n",
       " 'first_bias': tensor([[0., 0., 0., 0.]], requires_grad=True),\n",
       " 'second_linear': tensor([[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]], requires_grad=True),\n",
       " 'second_bias': tensor([[0.]], requires_grad=True)}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dimension vector:\n",
    "n = (1,4,1)\n",
    "\n",
    "\n",
    "\n",
    "# Parameters:\n",
    "initial_params = {'first_linear' : torch.ones([n[0], n[1]], requires_grad=True), \\\n",
    "          'first_bias' : torch.zeros([1, n[1]], requires_grad=True), \\\n",
    "          'second_linear' : torch.ones([n[1], n[2]], requires_grad= True), \\\n",
    "          'second_bias' : torch.zeros([1, n[2]], requires_grad=True)}\n",
    "initial_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "molecular-snake",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "integrated-passport",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_input.shape = [batch_size, input_size]\n",
    "# w.shape = [input_size, output_size]\n",
    "# b.shape = [1,ouptut_size]\n",
    "def affine_linear(x_input, w, b):\n",
    "    return  x_input.transpose(0,1) * w + b\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1/ (1 + math.exp(-z))\n",
    "\n",
    "def radial_sigmoid(v): \n",
    "    return sigmoid(torch.linalg.norm(v).item())*v\n",
    "\n",
    "def ReLU(z):\n",
    "    return z*(z >= 0)\n",
    "\n",
    "def radial_ReLU(v): \n",
    "    return ReLU(torch.linalg.norm(v[1]).item())*v\n",
    "\n",
    "def radial_abs(v): \n",
    "    return abs(torch.linalg.norm(v).item())*v\n",
    "\n",
    "def radial_square(v): \n",
    "    return ((torch.linalg.norm(v).item())**2)*v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-dispatch",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "nervous-printer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.1428,  0.8035,  1.7134,  1.6157],\n",
       "        [ 2.7758,  0.6288,  1.2785,  1.2078],\n",
       "        [ 2.4089,  0.4540,  0.8436,  0.8000],\n",
       "        [ 2.0419,  0.2793,  0.4088,  0.3921],\n",
       "        [ 1.6750,  0.1046, -0.0261, -0.0158],\n",
       "        [ 1.3080, -0.0701, -0.4610, -0.4237],\n",
       "        [ 0.9410, -0.2449, -0.8958, -0.8315],\n",
       "        [ 0.5741, -0.4196, -1.3307, -1.2394],\n",
       "        [ 0.2071, -0.5943, -1.7656, -1.6473],\n",
       "        [-0.1599, -0.7691, -2.2004, -2.0551],\n",
       "        [-0.5268, -0.9438, -2.6353, -2.4630],\n",
       "        [-0.8938, -1.1185, -3.0702, -2.8709],\n",
       "        [-1.2607, -1.2933, -3.5050, -3.2787]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z1 = first_linear(x_small)\n",
    "z1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "primary-literacy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(4.0086, grad_fn=<CopyBackwards>), tensor(4.0086))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linalg.norm(z1[0]), torch.linalg.norm(torch.tensor([ 3.1428,  0.8035,  1.7134,  1.6157]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "drawn-earthquake",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.0086],\n",
       "        [3.3457],\n",
       "        [2.7130],\n",
       "        [2.1373],\n",
       "        [1.6785],\n",
       "        [1.4518],\n",
       "        [1.5619],\n",
       "        [1.9526],\n",
       "        [2.4954],\n",
       "        [3.1117],\n",
       "        [3.7656],\n",
       "        [4.4405],\n",
       "        [5.1281]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norms_z1 = torch.tensor([torch.linalg.norm(z1[i]) for i in range(len(z1))]).unsqueeze(1)\n",
    "norms_z1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "alternative-dynamics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 12.5982,   3.2210,   6.8682,   6.4767],\n",
       "        [  9.2873,   2.1037,   4.2775,   4.0411],\n",
       "        [  6.5353,   1.2318,   2.2888,   2.1703],\n",
       "        [  4.3643,   0.5970,   0.8737,   0.8380],\n",
       "        [  2.8114,   0.1755,  -0.0438,  -0.0265],\n",
       "        [  1.8990,  -0.1018,  -0.6692,  -0.6151],\n",
       "        [  1.4698,  -0.3825,  -1.3992,  -1.2987],\n",
       "        [  1.1209,  -0.8193,  -2.5983,  -2.4200],\n",
       "        [  0.5168,  -1.4831,  -4.4057,  -4.1105],\n",
       "        [ -0.4974,  -2.3931,  -6.8470,  -6.3949],\n",
       "        [ -1.9838,  -3.5539,  -9.9234,  -9.2746],\n",
       "        [ -3.9688,  -4.9668, -13.6330, -12.7480],\n",
       "        [ -6.4652,  -6.6320, -17.9741, -16.8137]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z1*norms_z1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "accessory-motivation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 12.5982,   3.2210,   6.8682,   6.4767],\n",
       "        [  9.2873,   2.1037,   4.2775,   4.0411],\n",
       "        [  6.5353,   1.2318,   2.2888,   2.1703],\n",
       "        [  4.3643,   0.5970,   0.8737,   0.8380],\n",
       "        [  2.8114,   0.1755,  -0.0438,  -0.0265],\n",
       "        [  1.8990,  -0.1018,  -0.6692,  -0.6151],\n",
       "        [  1.4698,  -0.3825,  -1.3992,  -1.2987],\n",
       "        [  1.1209,  -0.8193,  -2.5983,  -2.4200],\n",
       "        [  0.5168,  -1.4831,  -4.4057,  -4.1105],\n",
       "        [ -0.4974,  -2.3931,  -6.8470,  -6.3949],\n",
       "        [ -1.9838,  -3.5539,  -9.9234,  -9.2746],\n",
       "        [ -3.9688,  -4.9668, -13.6330, -12.7480],\n",
       "        [ -6.4652,  -6.6320, -17.9741, -16.8137]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norms_z1*z1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "floral-solomon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.0868,  0.7892,  1.6828,  1.5869],\n",
       "        [ 2.6814,  0.6074,  1.2350,  1.1667],\n",
       "        [ 2.2590,  0.4258,  0.7911,  0.7502],\n",
       "        [ 1.8265,  0.2498,  0.3656,  0.3507],\n",
       "        [ 1.4115,  0.0881, -0.0220, -0.0133],\n",
       "        [ 1.0598, -0.0568, -0.3735, -0.3433],\n",
       "        [ 0.7779, -0.2024, -0.7405, -0.6874],\n",
       "        [ 0.5027, -0.3675, -1.1653, -1.0854],\n",
       "        [ 0.1913, -0.5491, -1.6311, -1.5218],\n",
       "        [-0.1530, -0.7363, -2.1066, -1.9675],\n",
       "        [-0.5149, -0.9224, -2.5757, -2.4073],\n",
       "        [-0.8834, -1.1055, -3.0344, -2.8374],\n",
       "        [-1.2533, -1.2856, -3.4844, -3.2594]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sigmoid(norms_z1)*z1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "harmful-memorial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 12.5982,   3.2210,   6.8682,   6.4767],\n",
       "        [  9.2873,   2.1037,   4.2775,   4.0411],\n",
       "        [  6.5353,   1.2318,   2.2888,   2.1703],\n",
       "        [  4.3643,   0.5970,   0.8737,   0.8380],\n",
       "        [  2.8114,   0.1755,  -0.0438,  -0.0265],\n",
       "        [  1.8990,  -0.1018,  -0.6692,  -0.6151],\n",
       "        [  1.4698,  -0.3825,  -1.3992,  -1.2987],\n",
       "        [  1.1209,  -0.8193,  -2.5983,  -2.4200],\n",
       "        [  0.5168,  -1.4831,  -4.4057,  -4.1105],\n",
       "        [ -0.4974,  -2.3931,  -6.8470,  -6.3949],\n",
       "        [ -1.9838,  -3.5539,  -9.9234,  -9.2746],\n",
       "        [ -3.9688,  -4.9668, -13.6330, -12.7480],\n",
       "        [ -6.4652,  -6.6320, -17.9741, -16.8137]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.relu(norms_z1)*z1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "smart-laugh",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.0501e+01,  1.2912e+01,  2.7532e+01,  2.5962e+01],\n",
       "        [ 3.1073e+01,  7.0386e+00,  1.4311e+01,  1.3520e+01],\n",
       "        [ 1.7731e+01,  3.3420e+00,  6.2095e+00,  5.8881e+00],\n",
       "        [ 9.3280e+00,  1.2760e+00,  1.8673e+00,  1.7912e+00],\n",
       "        [ 4.7189e+00,  2.9465e-01, -7.3545e-02, -4.4462e-02],\n",
       "        [ 2.7569e+00, -1.4785e-01, -9.7160e-01, -8.9295e-01],\n",
       "        [ 2.2956e+00, -5.9736e-01, -2.1853e+00, -2.0285e+00],\n",
       "        [ 2.1886e+00, -1.5997e+00, -5.0733e+00, -4.7251e+00],\n",
       "        [ 1.2896e+00, -3.7008e+00, -1.0994e+01, -1.0257e+01],\n",
       "        [-1.5478e+00, -7.4465e+00, -2.1306e+01, -1.9899e+01],\n",
       "        [-7.4700e+00, -1.3383e+01, -3.7367e+01, -3.4924e+01],\n",
       "        [-1.7623e+01, -2.2055e+01, -6.0537e+01, -5.6607e+01],\n",
       "        [-3.3154e+01, -3.4009e+01, -9.2173e+01, -8.6222e+01]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(norms_z1**2)*z1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-muslim",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "decreased-zambia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.3570, 0.5590, 0.5820, 0.8190, 0.5630, 0.4890, 0.3390, 0.2180, 0.4840,\n",
       "          0.6040, 0.6840],\n",
       "         [1.2140, 1.6180, 1.6640, 2.1380, 1.6260, 1.4780, 1.1780, 0.9360, 1.4680,\n",
       "          1.7080, 1.8680]]),\n",
       " torch.Size([2, 11]),\n",
       " torch.Size([11]),\n",
       " torch.Size([1, 2]),\n",
       " torch.Size([2, 1]),\n",
       " torch.Size([11, 2]),\n",
       " torch.Size([1, 2]))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([3.57, 5.59, 5.82, 8.19, 5.63, 4.89, 3.39, 2.18, 4.84, 6.04, 6.84])*0.1\n",
    "w = torch.tensor([[1.0, 2.0]])\n",
    "b = torch.tensor([[0.0, 0.5]])\n",
    "z = x*(w.transpose(0,1)) + b.transpose(0,1)\n",
    "z, z.shape, x.shape, w.shape, w.transpose(0,1).shape, z.transpose(0,1).shape, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "rental-private",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3570, 1.2140],\n",
       "        [0.5590, 1.6180],\n",
       "        [0.5820, 1.6640],\n",
       "        [0.8190, 2.1380],\n",
       "        [0.5630, 1.6260],\n",
       "        [0.4890, 1.4780],\n",
       "        [0.3390, 1.1780],\n",
       "        [0.2180, 0.9360],\n",
       "        [0.4840, 1.4680],\n",
       "        [0.6040, 1.7080],\n",
       "        [0.6840, 1.8680]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[3.57, 5.59, 5.82, 8.19, 5.63, 4.89, 3.39, 2.18, 4.84, 6.04, 6.84]])*0.1\n",
    "z = x.transpose(0,1)*(w) + b\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "elementary-treasury",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3556, 1.2091],\n",
       "        [0.5567, 1.6115],\n",
       "        [0.5796, 1.6573],\n",
       "        [0.8157, 2.1294],\n",
       "        [0.5607, 1.6194],\n",
       "        [0.4870, 1.4720],\n",
       "        [0.3376, 1.1732],\n",
       "        [0.2171, 0.9322],\n",
       "        [0.4820, 1.4621],\n",
       "        [0.6016, 1.7011],\n",
       "        [0.6812, 1.8604]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = linear_part(x, w, b)\n",
    "radial_sigmoid(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "accessory-relevance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2784, 0.9469])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "radial_sigmoid(torch.tensor([0.3570, 1.2140]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "alone-auction",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-114-2157d3144052>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3.57\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5.59\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5.82\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8.19\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5.63\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4.89\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3.39\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.18\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4.84\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6.04\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6.84\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0my_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0my_p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-112-b470b46770b8>\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(x_input, w, b, v, c)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0maffine_linear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mradial_sigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maffine_linear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-111-14e457b79177>\u001b[0m in \u001b[0;36maffine_linear\u001b[0;34m(x_input, w, b)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# b.shape = [1,ouptut_size]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0maffine_linear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mreturn\u001b[0m  \u001b[0mx_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([3.57, 5.59, 5.82, 8.19, 5.63, 4.89, 3.39, 2.18, 4.84, 6.04, 6.84])*0.1\n",
    "y = torch.tensor([0, 1, 1, 1, 1, 1 , 0, 0, 0, 1, 1])\n",
    "y_p = model(x, torch.tensor([1.0,-1.0]), torch.tensor([0.0,0.0]), torch.tensor([2.0, 1.0]), torch.tensor([0.5]))\n",
    "y_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "sudden-theme",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.5686)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(y_p, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "removed-passage",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 4 at dim 1 (got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-8413dd9cfac4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: expected sequence of length 4 at dim 1 (got 1)"
     ]
    }
   ],
   "source": [
    "params = torch.tensor([[[1.0],[1.0],[1.0],[1.0]],[[0.0],[0.0],[0.0],[0.0]], [[1.0],[1.0],[1.0],[1.0]],[[0]]], requires_grad=True)\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "official-columbus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(5.), 5.0)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([3.0,4.0])\n",
    "torch.linalg.norm(a), torch.linalg.norm(a).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "deluxe-testament",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Made-up data\n",
    "x = torch.tensor([3.57, 5.59, 5.82, 8.19, 5.63, 4.89, 3.39, 2.18, 4.84, 6.04, 6.84])\n",
    "y = torch.tensor([0, 1, 1, 1, 1, 1 , 0, 0, 0, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "designing-meaning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(17.9858),\n",
       " 0.9999999845516783,\n",
       " tensor([3.5700, 5.5900, 5.8200, 8.1900, 5.6300, 4.8900, 3.3900, 2.1800, 4.8400,\n",
       "         6.0400, 6.8400]))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linalg.norm(x), sigmoid(torch.linalg.norm(x)), radial_sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ecological-hungarian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.7986),\n",
       " 0.8579755909315562,\n",
       " tensor([0.3063, 0.4796, 0.4993, 0.7027, 0.4830, 0.4196, 0.2909, 0.1870, 0.4153,\n",
       "         0.5182, 0.5869]))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linalg.norm(x*0.1), sigmoid(torch.linalg.norm(x*0.1)), radial_sigmoid(x*0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "published-updating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(17.9858),\n",
       " tensor([ 64.2092, 100.5404, 104.6772, 147.3034, 101.2599,  87.9504,  60.9717,\n",
       "          39.2090,  87.0511, 108.6340, 123.0226]))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linalg.norm(x), radial_abs(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "turned-disease",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(17.9858),\n",
       " tensor([ 64.2092, 100.5404, 104.6772, 147.3034, 101.2599,  87.9504,  60.9717,\n",
       "          39.2090,  87.0511, 108.6340, 123.0226]))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linalg.norm(x), radial_ReLU(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "moral-program",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(17.9858),\n",
       " tensor([1154.8513, 1808.2966, 1882.6989, 2649.3647, 1821.2361, 1581.8551,\n",
       "         1096.6235,  705.2034, 1565.6808, 1953.8661, 2212.6562]))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linalg.norm(x), radial_square(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
