{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T03:39:07.818433Z",
     "start_time": "2022-03-10T03:39:06.805707Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: cpu\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Dict, Tuple\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "dev = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    dev = 'cuda:0'\n",
    "print(\"Running on:\",dev)\n",
    "device = torch.device(dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quivers and quiver representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quiver class is designed to define an acyclic quiver with no double edges. The initial quiver is not required to have a bias vertex; such a vertex can be added with the ```add_bias()``` method.\n",
    "\n",
    "The input list of vertices is meant to be a list of strings, one for each vertex. It is best to avoid the label ```bias``` among the vertices. \n",
    "\n",
    "The input list of edges is meant to be a tuple ```e = (e[0], e[1])``` where ```e[0]``` is the source and ```e[1]``` is the target. No double edges or loops are allowed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T03:39:08.143331Z",
     "start_time": "2022-03-10T03:39:08.128176Z"
    }
   },
   "outputs": [],
   "source": [
    "class quiver:\n",
    "    \"\"\"Quiver class. Vertices are given as a list of strings. Edges are given as a list of pairs.\n",
    "    \n",
    "    Attributes and Methods.\n",
    "    \"\"\"\n",
    "    def __init__(self, vertices : List[str], edges : List[Tuple[str]]):\n",
    "        self.vertices = vertices\n",
    "        # Add assert to check no repeated vertices\n",
    "        # E.g. assert len(set(vertices)) == len(vertices)\n",
    "        # Assert there is no bias initially, or if there is, it has the desired properties\n",
    "        \n",
    "        self.edges = edges\n",
    "        # Add assert to check that edges is a list of pairs\n",
    "        # First entry of the pair is the sourse, second is the target\n",
    "        # Source and target of each edge should be in the vertex set      \n",
    "        # Separate class for edges? vertices?\n",
    "        \n",
    "        # Get the sources and sinks\n",
    "        sources = set(self.vertices)\n",
    "        sinks = set(self.vertices)\n",
    "        for e in self.edges:\n",
    "            sources.discard(e[1])\n",
    "            sinks.discard(e[0])\n",
    "        self.sources = sources\n",
    "        self.sinks = sinks\n",
    "    \n",
    "    # Check that the quiver is acyclic\n",
    "    def check_acyclic(self):\n",
    "        None\n",
    "        # One way: find all sources, do depth-first search\n",
    "        \n",
    "    # Check that the vertices are in topological order    \n",
    "    def check_top_order(self):\n",
    "        indices = {}\n",
    "        for i,v in enumerate(self.vertices):\n",
    "            indices[v] = i\n",
    "        return all([indices[e[0]] <  indices[e[1]] for e in self.edges])\n",
    "        \n",
    "    # Get the incoming edges for every vertex\n",
    "    def get_incoming(self, vertex):\n",
    "        assert vertex in self.vertices, \"No such vertex found\"\n",
    "        return [e for e in self.edges if e[1] == vertex]\n",
    "        # Can get the incoming neighbors as [e[1] for e in self.get_incoming(vertex)]\n",
    "        \n",
    "    # Add a bias vertex. Considering alternatives to this ... \n",
    "    def add_bias(self):\n",
    "        # Add bias vertex. This will not disturb the topological order.\n",
    "        for v in self.vertices:\n",
    "            if v not in self.sources:\n",
    "                self.edges.append(('bias', v))\n",
    "        self.vertices = ['bias'] + self.vertices\n",
    "        return\n",
    "    \n",
    "    #########\n",
    "    # Check if a vertex is a sink (Don't really need this any more)\n",
    "    def is_sink(self, vertex):\n",
    "        assert vertex in self.vertices, \"No such vertex found\"\n",
    "        return all([e[0] != vertex for e in self.edges])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T03:39:08.737445Z",
     "start_time": "2022-03-10T03:39:08.708218Z"
    }
   },
   "outputs": [],
   "source": [
    "class quiver_rep:\n",
    "    \"\"\"Quiver representation class. Input a quiver with dimension vector and a matrix for each edge.\"\"\"\n",
    "    def __init__(self, quiver: quiver, dims: Dict[str,int], matrices: Dict[str, np.array]):\n",
    "        self.quiver = quiver\n",
    "        self.dims = dims\n",
    "        self.matrices = matrices\n",
    "        \n",
    "        # Check the dimension vector\n",
    "        assert len(dims) == len(self.quiver.vertices), \"Inappropriate dimension vector\"\n",
    "        for v in dims:\n",
    "            assert v in self.quiver.vertices, \"Inappropriate dim vector\"\n",
    "            assert isinstance(dims[v], int) and dims[v] >=0, \"Dimension needs to be a positive integer\"\n",
    "        \n",
    "        if 'bias' in dims:\n",
    "            assert dims['bias'] == 1, \"Dimension at bias needs to be 1\"\n",
    "\n",
    "            \n",
    "        # Check the matrices\n",
    "        assert len(matrices) == len(self.quiver.edges), \"Matrices error\"\n",
    "        for e in matrices:\n",
    "            assert e in self.quiver.edges, \"Matrices error\"\n",
    "            assert isinstance(matrices[e], np.ndarray), \"Matrices error\" # May need fixing\n",
    "            assert np.shape(matrices[e]) == (dims[e[1]], dims[e[0]]), \"Dimension error\"\n",
    "            \n",
    "            \n",
    "    # Compute the reduced dimension vector\n",
    "    def comp_dims_red(self) -> Dict:\n",
    "        \n",
    "        assert self.quiver.check_top_order(), \"Order of the vertices is not topological\"\n",
    "\n",
    "        dims_red = {}\n",
    "        for i in self.quiver.vertices:\n",
    "            if i == 'bias' or i in self.quiver.sources or i in self.quiver.sinks:\n",
    "                dims_red[i] = self.dims[i]\n",
    "            else:\n",
    "                incoming = self.quiver.get_incoming(i)\n",
    "                dims_red[i] = min(self.dims[i], sum([dims_red[e[0]] for e in incoming]) )\n",
    "\n",
    "                    \n",
    "        self.dims_red = dims_red        \n",
    "        return dims_red\n",
    "    \n",
    "    \n",
    "    # Auxiliary function\n",
    "    def padzeros(self, M, newrows, newcols = None):\n",
    "        oldrows, oldcols = M.shape\n",
    "        if newcols == None:\n",
    "            newcols = oldcols\n",
    "        return np.pad(M,((0,newrows-oldrows),(0,newcols-oldcols)),mode=\"constant\")\n",
    " \n",
    "    \n",
    "    # QR dimensional reduction algorithm\n",
    "    def QRDimRed(self, verbose : bool = False ):\n",
    "        dims = self.dims\n",
    "        matrices = self.matrices\n",
    "        quiver = self.quiver\n",
    "        vertices = quiver.vertices\n",
    "        edges = quiver.edges\n",
    "\n",
    "        # Check that vertices are in a topological order\n",
    "        assert quiver.check_top_order(), \"Order of the vertices is not topological\"\n",
    "\n",
    "        # Compute the reduced dimension vector\n",
    "        dims_red = self.comp_dims_red()\n",
    "        # print(dims, dims_red)\n",
    "\n",
    "        # Q = dictionary mapping each vertex to an orthogonal matrix\n",
    "        Q = {}\n",
    "\n",
    "        # Vmatrices = matrices of the reduced representation V, mapping each edge to a matrix\n",
    "        Vmatrices = {}\n",
    "\n",
    "        if verbose:\n",
    "            print(quiver.edges)\n",
    "            print(quiver.vertices)\n",
    "\n",
    "        for i in vertices:\n",
    "            incoming = quiver.get_incoming(i)\n",
    "\n",
    "            # Case of a source vertex\n",
    "            if incoming == []:\n",
    "                Q[i] = np.eye(dims[i])\n",
    "\n",
    "            # Case of a hidden vertex    \n",
    "            elif i not in quiver.sinks:\n",
    "\n",
    "                # Compute the matrix to be QR-decomposed\n",
    "                M = np.array([])\n",
    "                for e in incoming:\n",
    "                    # Transform weights on incoming edges\n",
    "                    Qj = Q[e[0]]\n",
    "                    Me = matrices[e] @ Qj[:,:dims_red[e[0]]]\n",
    "                    if np.shape(M) == (0,):\n",
    "                        M = Me\n",
    "                    else:\n",
    "                        M = np.hstack((M, Me))\n",
    "\n",
    "                Q[i], R = np.linalg.qr(M, mode=\"complete\")\n",
    "\n",
    "                # Case of reduction \n",
    "                if dims_red[i] < dims[i]: \n",
    "                    R = R[:dims_red[i]]\n",
    "\n",
    "                # Process and add to the dictionaries\n",
    "                for e in incoming:                       \n",
    "                    # Extract V_e from R_i for all incoming edges e\n",
    "                    Vmatrices[e] = R[:,:dims_red[e[0]]]\n",
    "                    R = R[:,dims_red[e[0]]:]\n",
    "\n",
    "            # Case of a sink (no reduction)\n",
    "            else:\n",
    "                Q[i] = np.eye(dims[i])\n",
    "                for e in incoming:\n",
    "                    # Transform weights on incoming edges\n",
    "                    Qj = Q[e[0]]\n",
    "                    Vmatrices[e] = matrices[e] @ Qj[:,:dims_red[e[0]]]                \n",
    "\n",
    "\n",
    "        # Make V into a representation\n",
    "        V = quiver_rep(quiver, dims_red, Vmatrices)\n",
    "\n",
    "        # Verify that V is a subrepresentation of Q^{-1} W  \n",
    "        for e in quiver.edges:\n",
    "            Qi = Q[e[0]]\n",
    "            Qj = Q[e[1]]\n",
    "            max_diff = np.max(np.abs(np.transpose(Qj) @ matrices[e] @ Qi[:,:dims_red[e[0]]] \n",
    "                         - self.padzeros(Vmatrices[e], dims[e[1]])))\n",
    "            assert max_diff < 1e-10, \"Error in the algorithm\"\n",
    "\n",
    "        return Q, V\n",
    "    \n",
    "    \n",
    "    def reduced_representation(self, verbose : bool = False ):\n",
    "        return self.QRDimRed(verbose)[1]\n",
    "                \n",
    "    def transformed_representation(self):\n",
    "        Q, V = self.QRDimRed()\n",
    "        transformed_mat_dict = {}\n",
    "        for e in self.quiver.edges:\n",
    "            transformed_mat_dict[e] = np.transpose(Q[e[1]]) @ self.matrices[e] @ Q[e[0]]\n",
    "        \n",
    "        Q_inv_W = quiver_rep(self.quiver, self.dims, transformed_mat_dict)\n",
    "        \n",
    "        return Q_inv_W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T00:41:27.213007Z",
     "start_time": "2022-03-01T00:41:27.206820Z"
    }
   },
   "source": [
    "### Linear Feedforward Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T03:39:09.691327Z",
     "start_time": "2022-03-10T03:39:09.673643Z"
    }
   },
   "outputs": [],
   "source": [
    "# Linear feedforward function, ignoring biases\n",
    "# Might turn out not to be super necessary\n",
    "\n",
    "def lin_ff(W : quiver_rep) -> np.array:\n",
    "    dims = W.dims\n",
    "    matrices = W.matrices\n",
    "    quiver = W.quiver\n",
    "    vertices = quiver.vertices\n",
    "    edges = quiver.edges\n",
    "    \n",
    "    assert quiver.check_top_order(), \"Order of the vertices is not topological\"\n",
    "    \n",
    "    # Dictionary for partial feedforward functions:\n",
    "    partial = {}\n",
    "    input_dim = 0\n",
    "    # input_dim = sum( [dims[i] for i in quiver.sources])\n",
    "    \n",
    "    for i in quiver.vertices:\n",
    "        incoming = quiver.get_incoming(i)\n",
    "        \n",
    "        # Case of a source\n",
    "        if i in quiver.sources:\n",
    "            \n",
    "            # Update matrices already defined\n",
    "            for j in partial:\n",
    "                partial[j] = np.hstack((partial[j], np.zeros((dims[j],dims[i]))))\n",
    "                \n",
    "            # Define the new matrix as a projection matrix\n",
    "            if input_dim == 0:\n",
    "                partial[i] = np.eye(dims[i])\n",
    "            else:\n",
    "                partial[i] = np.hstack((np.zeros((dims[i], input_dim)), np.eye(dims[i])))\n",
    "            input_dim += dims[i]\n",
    "\n",
    "        # Case of a hidden vertex or a sink\n",
    "        else:\n",
    "            \n",
    "            # Compute the matrix to be added\n",
    "            A = np.zeros((dims[i], input_dim))\n",
    "            for e in incoming:\n",
    "                # Ignore biases for now\n",
    "                if e[0] != 'bias':\n",
    "                    A += matrices[e] @ partial[e[0]]\n",
    "            partial[i] = A\n",
    "         \n",
    "    # Compute the final output matrix by stacking the matrices for sinks\n",
    "    result = np.array([])\n",
    "    for i in quiver.sinks:\n",
    "        if np.shape(result) == (0,):\n",
    "            result = partial[i]\n",
    "        else:\n",
    "            result = np.vstack((result, partial[i]))\n",
    "                        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensional reduction algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T03:39:10.624768Z",
     "start_time": "2022-03-10T03:39:10.621627Z"
    }
   },
   "outputs": [],
   "source": [
    "# Auxiliary function\n",
    "\n",
    "def padzeros(M,newrows,newcols = None):\n",
    "    oldrows, oldcols = M.shape\n",
    "    if newcols == None:\n",
    "        newcols = oldcols\n",
    "    return np.pad(M,((0,newrows-oldrows),(0,newcols-oldcols)),mode=\"constant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T03:39:11.100556Z",
     "start_time": "2022-03-10T03:39:11.079482Z"
    }
   },
   "outputs": [],
   "source": [
    "# QR dimensional reduction algorithm\n",
    "# This is incorporated in the quiver_rep class\n",
    "\n",
    "def QRDimRed(W : quiver_rep, verbose : bool = False ):\n",
    "    dims = W.dims\n",
    "    matrices = W.matrices\n",
    "    quiver = W.quiver\n",
    "    vertices = quiver.vertices\n",
    "    edges = quiver.edges\n",
    "    \n",
    "    # Check that vertices are in a topological order\n",
    "    assert quiver.check_top_order(), \"Order of the vertices is not topological\"\n",
    "    \n",
    "    # Compute the reduced dimension vector\n",
    "    dims_red = W.comp_dims_red()\n",
    "    # print(dims, dims_red)\n",
    "    \n",
    "    # Q = dictionary mapping each vertex to an orthogonal matrix\n",
    "    Q = {}\n",
    "    \n",
    "    # Vmatrices = matrices of the reduced representation V, mapping each edge to a matrix\n",
    "    Vmatrices = {}\n",
    "    \n",
    "    if verbose:\n",
    "        print(quiver.edges)\n",
    "        print(quiver.vertices)\n",
    "    \n",
    "    for i in vertices:\n",
    "        incoming = quiver.get_incoming(i)\n",
    "        \n",
    "        # Case of a source vertex\n",
    "        if incoming == []:\n",
    "            Q[i] = np.eye(dims[i])\n",
    "            \n",
    "        # Case of a hidden vertex    \n",
    "        elif i not in quiver.sinks:\n",
    "            \n",
    "            # Compute the matrix to be QR-decomposed\n",
    "            M = np.array([])\n",
    "            for e in incoming:\n",
    "                # Transform weights on incoming edges\n",
    "                Qj = Q[e[0]]\n",
    "                Me = matrices[e] @ Qj[:,:dims_red[e[0]]]\n",
    "                if np.shape(M) == (0,):\n",
    "                    M = Me\n",
    "                else:\n",
    "                    M = np.hstack((M, Me))\n",
    "                    \n",
    "            Q[i], R = np.linalg.qr(M, mode=\"complete\")\n",
    "\n",
    "            # Case of reduction \n",
    "            if dims_red[i] < dims[i]: \n",
    "                R = R[:dims_red[i]]\n",
    "                \n",
    "            # Process and add to the dictionaries\n",
    "            for e in incoming:                       \n",
    "                # Extract V_e from R_i for all incoming edges e\n",
    "                Vmatrices[e] = R[:,:dims_red[e[0]]]\n",
    "                R = R[:,dims_red[e[0]]:]\n",
    "                \n",
    "        # Case of a sink (no reduction)\n",
    "        else:\n",
    "            Q[i] = np.eye(dims[i])\n",
    "            for e in incoming:\n",
    "                # Transform weights on incoming edges\n",
    "                Qj = Q[e[0]]\n",
    "                Vmatrices[e] = matrices[e] @ Qj[:,:dims_red[e[0]]]                \n",
    "\n",
    "    \n",
    "    # Make V into a representation\n",
    "    V = quiver_rep(quiver, dims_red, Vmatrices)\n",
    "\n",
    "    # Verify that V is a subrepresentation of Q^{-1} W  \n",
    "    for e in quiver.edges:\n",
    "        Qi = Q[e[0]]\n",
    "        Qj = Q[e[1]]\n",
    "        max_diff = np.max(np.abs(np.transpose(Qj) @ matrices[e] @ Qi[:,:dims_red[e[0]]] \n",
    "                     - padzeros(Vmatrices[e], dims[e[1]])))\n",
    "        assert max_diff < 1e-10, \"Error in the algorithm\"\n",
    "\n",
    "    return Q, V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T03:44:34.607962Z",
     "start_time": "2022-03-10T03:44:34.602274Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [('a', 'b')] [('a', 'c'), ('b', 'c')] [('c', 'd')]\n",
      "False False False True\n",
      "True\n",
      "{'a'}\n",
      "['bias', 'a', 'b', 'c', 'd']\n",
      "[('a', 'b'), ('a', 'c'), ('b', 'c'), ('c', 'd'), ('bias', 'b'), ('bias', 'c'), ('bias', 'd')]\n"
     ]
    }
   ],
   "source": [
    "# EXAMPLE\n",
    "# Quiver with skip connections and no bias\n",
    "\n",
    "vertex_list = ['a', 'b', 'c', 'd']\n",
    "edge_list = [('a', 'b'), ('a','c'), ('b','c'), ('c', 'd')]\n",
    "\n",
    "quiv_ex = quiver(vertex_list, edge_list)\n",
    "# print(Q.vertices, Q.edges)\n",
    "\n",
    "# Test the methods\n",
    "print(quiv_ex.get_incoming('a'), quiv_ex.get_incoming('b'), quiv_ex.get_incoming('c'), quiv_ex.get_incoming('d'))\n",
    "print(quiv_ex.is_sink('a'), quiv_ex.is_sink('b'), quiv_ex.is_sink('c'), quiv_ex.is_sink('d'))\n",
    "print(quiv_ex.check_top_order())\n",
    "print(quiv_ex.sources)\n",
    "quiv_ex.add_bias()\n",
    "print(quiv_ex.vertices)\n",
    "print(quiv_ex.edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T03:44:34.707229Z",
     "start_time": "2022-03-10T03:44:34.702497Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bias': 1, 'a': 2, 'b': 3, 'c': 6, 'd': 2}\n"
     ]
    }
   ],
   "source": [
    "# Representation of this quiver\n",
    "\n",
    "dim_vector = {'bias' : 1, 'a': 2, 'b': 4, 'c': 8, 'd': 2 }\n",
    "\n",
    "maps = {('a', 'b') : np.random.rand(4, 2), \n",
    "        ('a', 'c') : np.random.rand(8, 2), \n",
    "        ('b', 'c') : np.random.rand(8, 4),\n",
    "        ('c', 'd') : np.random.rand(2, 8),\n",
    "        ('bias', 'b') : np.random.rand(4, 1),\n",
    "        ('bias', 'c') : np.random.rand(8, 1),\n",
    "        ('bias', 'd') : np.random.rand(2, 1)}\n",
    "\n",
    "ex_rep = quiver_rep(quiv_ex, dim_vector, maps)\n",
    "print(ex_rep.comp_dims_red())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T03:44:35.192444Z",
     "start_time": "2022-03-10T03:44:35.149173Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bias': 1, 'a': 2, 'b': 3, 'c': 6, 'd': 2}\n",
      "[(1, 1), (2, 2), (4, 4), (8, 8), (2, 2)]\n",
      "[(3, 2), (3, 1), (6, 2), (6, 3), (6, 1), (2, 6), (2, 1)]\n"
     ]
    }
   ],
   "source": [
    "# Check the algorithm\n",
    "\n",
    "Q_ex ,V_ex = QRDimRed(ex_rep)\n",
    "print(ex_rep.comp_dims_red())\n",
    "print([np.shape(Q_ex[i]) for i in Q_ex])\n",
    "print([np.shape(V_ex.matrices[e]) for e in V_ex.matrices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T03:44:35.577256Z",
     "start_time": "2022-03-10T03:44:35.570738Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.82340345, 4.00647384],\n",
       "       [6.89748105, 6.66544329]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_ff(ex_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T03:44:36.012130Z",
     "start_time": "2022-03-10T03:44:36.006740Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.82340345, 4.00647384],\n",
       "       [6.89748105, 6.66544329]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_rep.matrices[('c','d')] @ ( ex_rep.matrices[('a','c')] + ex_rep.matrices[('b','c')] @ ex_rep.matrices[('a','b')] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T03:44:36.476596Z",
     "start_time": "2022-03-10T03:44:36.471132Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.82340345, 4.00647384],\n",
       "       [6.89748105, 6.66544329]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_ff(V_ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T03:44:37.416465Z",
     "start_time": "2022-03-10T03:44:37.409662Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [] [('a', 'c'), ('b', 'c')] [('c', 'd')] [('c', 'e')]\n",
      "False False False True True\n",
      "True\n",
      "{'a', 'b'}\n",
      "['bias', 'a', 'b', 'c', 'd', 'e']\n",
      "[('a', 'c'), ('b', 'c'), ('c', 'd'), ('c', 'e'), ('bias', 'c'), ('bias', 'd'), ('bias', 'e')]\n"
     ]
    }
   ],
   "source": [
    "# EXAMPLE\n",
    "# Quiver with multiple inputs and outputs\n",
    "\n",
    "vertex_list2 = ['a', 'b', 'c', 'd', 'e']\n",
    "edge_list2 = [('a', 'c'), ('b','c'), ('c','d'), ('c', 'e')]\n",
    "\n",
    "quiv_ex2 = quiver(vertex_list2, edge_list2)\n",
    "# print(Q.vertices, Q.edges)\n",
    "\n",
    "# Test the methods\n",
    "print(quiv_ex2.get_incoming('a'), quiv_ex2.get_incoming('b'), quiv_ex2.get_incoming('c'), \n",
    "      quiv_ex2.get_incoming('d'), quiv_ex2.get_incoming('e'))\n",
    "print(quiv_ex2.is_sink('a'), quiv_ex2.is_sink('b'), quiv_ex2.is_sink('c'), \n",
    "      quiv_ex2.is_sink('d'), quiv_ex2.is_sink('e'))\n",
    "print(quiv_ex2.check_top_order())\n",
    "print(quiv_ex2.sources)\n",
    "quiv_ex2.add_bias()\n",
    "print(quiv_ex2.vertices)\n",
    "print(quiv_ex2.edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T03:44:37.781859Z",
     "start_time": "2022-03-10T03:44:37.772630Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bias': 1, 'a': 1, 'b': 2, 'c': 4, 'd': 2, 'e': 6}\n"
     ]
    }
   ],
   "source": [
    "# Representation of this quiver\n",
    "\n",
    "dim_vector2 = {'bias' : 1, 'a': 1, 'b': 2, 'c': 8, 'd': 2 , 'e': 6}\n",
    "\n",
    "maps2 = {('a', 'c') : np.random.rand(8, 1), \n",
    "        ('b', 'c') : np.random.rand(8, 2), \n",
    "        ('c', 'd') : np.random.rand(2, 8),\n",
    "        ('c', 'e') : np.random.rand(6, 8),\n",
    "        ('bias', 'c') : np.random.rand(8, 1),\n",
    "        ('bias', 'd') : np.random.rand(2, 1),\n",
    "        ('bias', 'e') : np.random.rand(6, 1)}\n",
    "\n",
    "ex_rep2 = quiver_rep(quiv_ex2, dim_vector2, maps2)\n",
    "print(ex_rep2.comp_dims_red())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T03:44:37.994105Z",
     "start_time": "2022-03-10T03:44:37.982322Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bias': 1, 'a': 1, 'b': 2, 'c': 4, 'd': 2, 'e': 6}\n",
      "[(1, 1), (1, 1), (2, 2), (8, 8), (2, 2), (6, 6)]\n",
      "[(4, 1), (4, 2), (4, 1), (2, 4), (2, 1), (6, 4), (6, 1)]\n"
     ]
    }
   ],
   "source": [
    "# Check the algorithm\n",
    "\n",
    "Q_ex2 ,V_ex2 = QRDimRed(ex_rep2)\n",
    "print(ex_rep2.comp_dims_red())\n",
    "print([np.shape(Q_ex2[i]) for i in Q_ex2])\n",
    "print([np.shape(V_ex2.matrices[e]) for e in V_ex2.matrices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T03:44:38.463329Z",
     "start_time": "2022-03-10T03:44:38.457473Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.52282534, 2.25190429, 1.51265527],\n",
       "       [1.7596857 , 1.91761368, 1.32881942],\n",
       "       [2.01899698, 2.59637092, 1.43544403],\n",
       "       [1.23461802, 1.58681243, 1.22524236],\n",
       "       [1.41080149, 2.02532938, 1.31304906],\n",
       "       [1.20847464, 3.05876686, 1.61535514],\n",
       "       [1.65014247, 2.36447025, 1.12981411],\n",
       "       [1.609781  , 1.96903182, 1.14228554]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_ff(ex_rep2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T03:44:38.894210Z",
     "start_time": "2022-03-10T03:44:38.888217Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.52282534, 2.25190429, 1.51265527],\n",
       "       [1.7596857 , 1.91761368, 1.32881942],\n",
       "       [2.01899698, 2.59637092, 1.43544403],\n",
       "       [1.23461802, 1.58681243, 1.22524236],\n",
       "       [1.41080149, 2.02532938, 1.31304906],\n",
       "       [1.20847464, 3.05876686, 1.61535514],\n",
       "       [1.65014247, 2.36447025, 1.12981411],\n",
       "       [1.609781  , 1.96903182, 1.14228554]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_ff(V_ex2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T18:07:37.311622Z",
     "start_time": "2022-03-01T18:07:37.306316Z"
    }
   },
   "source": [
    "# Example 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T03:44:39.880455Z",
     "start_time": "2022-03-10T03:44:39.874512Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 2, 'b': 2, 'c': 2, 'd': 4, 'e': 2}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vertex_list2 = ['a', 'b', 'c', 'd', 'e']\n",
    "edge_list2 = [('a', 'b'), ('a','c'), ('b','d'), ('c', 'd'),('d','e')]\n",
    "\n",
    "quiv_ex2 = quiver(vertex_list2, edge_list2)\n",
    "\n",
    "dim_vector2 = {'a': 2, 'b': 3, 'c': 3, 'd': 6 , 'e': 2}\n",
    "\n",
    "maps2 = {('a', 'b') : np.random.rand(3, 2), \n",
    "        ('a', 'c') : np.random.rand(3, 2), \n",
    "        ('b', 'd') : np.random.rand(6, 3),\n",
    "        ('c', 'd') : np.random.rand(6, 3),\n",
    "        ('d', 'e') : np.random.rand(2, 6)}\n",
    "\n",
    "ex_rep2 = quiver_rep(quiv_ex2, dim_vector2, maps2)\n",
    "print(ex_rep2.comp_dims_red())\n",
    "\n",
    "Q_ex2 ,V_ex2 = QRDimRed(ex_rep2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T03:44:40.357704Z",
     "start_time": "2022-03-10T03:44:40.348330Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('a', 'b')\n",
      "[[-0.84986284 -0.41623583]\n",
      " [ 0.          0.35188916]]\n",
      "\n",
      "('a', 'c')\n",
      "[[-1.06456798 -0.89566483]\n",
      " [ 0.          0.36804557]]\n",
      "\n",
      "('b', 'd')\n",
      "[[ 2.04742221 -0.54182444]\n",
      " [ 0.         -0.99042812]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]]\n",
      "\n",
      "('c', 'd')\n",
      "[[ 1.4646289  -1.17082291]\n",
      " [ 0.54771019  0.00367763]\n",
      " [ 0.83228108 -0.25413824]\n",
      " [ 0.         -0.25010203]]\n",
      "\n",
      "('d', 'e')\n",
      "[[-1.24492312 -0.76287917 -0.07643738  0.15334637]\n",
      " [-1.00145785 -1.0002676  -0.30797396  0.11532174]]\n"
     ]
    }
   ],
   "source": [
    "for e in V_ex2.quiver.edges:\n",
    "    print()\n",
    "    print(e)\n",
    "    print(V_ex2.matrices[e])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiver Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T03:44:41.676756Z",
     "start_time": "2022-03-10T03:44:41.672961Z"
    }
   },
   "outputs": [],
   "source": [
    "class RadAct(nn.Module):\n",
    "    def __init__(self, eta = F.relu):\n",
    "        super().__init__()\n",
    "        self.eta = eta\n",
    "        self.shift = 0 \n",
    "        # Add internal bias/shift later\n",
    "        \n",
    "    def forward(self,x):\n",
    "        # x: [Batch x Channel]\n",
    "        # Radial activations\n",
    "        r = torch.linalg.norm(x, dim=-1) \n",
    "        if torch.min(r) < 1e-6:\n",
    "            r += 1e-6\n",
    "        scalar = self.eta(r + self.shift) / r\n",
    "        return x * scalar.unsqueeze(-1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T03:44:42.328569Z",
     "start_time": "2022-03-10T03:44:42.316719Z"
    }
   },
   "outputs": [],
   "source": [
    "class QuiverNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, eta: float , quiver: quiver, dims: Dict[str,int] ):\n",
    "        super().__init__()\n",
    "        self.eta = eta\n",
    "        self.quiver = quiver\n",
    "        self.dims = dims\n",
    "        self.matrices = nn.ModuleDict()\n",
    "        \n",
    "        # Linear layer for each edge\n",
    "        for e in quiver.edges:\n",
    "            self.matrices[self.edge_tup_to_str(e)] = nn.Linear(self.dims[e[0]], self.dims[e[1]], bias = False)\n",
    "        \n",
    "        assert quiver.check_top_order(), \"Vertices not in topological order.\"\n",
    "        \n",
    "        # Radial activations\n",
    "        self.act = RadAct(self.eta)\n",
    "        \n",
    "        # Add assert statement to check that dims is a dimension vector for Q\n",
    "          \n",
    "    # Encode each edge as a string\n",
    "    def edge_tup_to_str(self, e : Tuple[str]):\n",
    "        assert e in self.quiver.edges\n",
    "        (t,h) = e\n",
    "        return t + \" to \" + h\n",
    "    \n",
    "    # Extract the (source, target) pair from each string encoding an edge\n",
    "    def edge_str_to_tup(self, e_str : str):\n",
    "        t,to,h = e_str.split()\n",
    "        assert (t,h) in self.quiver.edges\n",
    "        return (t,h)\n",
    "    \n",
    "    # Get the matrix of an edge\n",
    "    def get_matrix(self, e):\n",
    "        return self.matrices[self.edge_tup_to_str(e)].weight\n",
    "\n",
    "\n",
    "    # The feedforward function\n",
    "    def forward(self, x, non_linear = True):\n",
    "        \n",
    "        # Initialize Data Flow\n",
    "        h = {}\n",
    "        \n",
    "        # Bias \n",
    "        h['bias'] = torch.tensor(1.0)\n",
    "        \n",
    "        # Sources\n",
    "        for v in self.quiver.sources:\n",
    "            h[v] = x[v]\n",
    "            batch_size = x[v].shape[0]\n",
    "        \n",
    "        # Assert batchsize is same for all sources \n",
    "        \n",
    "        for v in self.quiver.vertices:\n",
    "            \n",
    "            # Non-source vertices\n",
    "            if v not in self.quiver.sources:\n",
    "                h[v] = torch.zeros(batch_size,self.dims[v])\n",
    "                for e in self.quiver.get_incoming(v):\n",
    "                    e_lin = self.matrices[self.edge_tup_to_str(e)]\n",
    "                    h[e[1]] += e_lin(h[e[0]])\n",
    "                if non_linear:\n",
    "                    h[v] = self.act(h[v])\n",
    "        \n",
    "        # Feedforward function output\n",
    "        out = {}\n",
    "        for v in self.quiver.sinks:\n",
    "            out[v] = h[v]\n",
    "            \n",
    "        return out\n",
    "            \n",
    "    \n",
    "    def set_weights(self, new_weights: quiver_rep):\n",
    "        assert new_weights.quiver == self.quiver, \"weights have different quiver\"\n",
    "        \n",
    "        for e in self.quiver.edges:\n",
    "            self.matrices[self.edge_tup_to_str(e)].weight = \\\n",
    "                torch.nn.Parameter(torch.tensor(new_weights.matrices[e],dtype = torch.float))\n",
    "        self.dims = new_weights.dims\n",
    "\n",
    "    def export_weights(self) -> quiver_rep:\n",
    "        quiver_rep_matrix_dict = {}\n",
    "        for e in self.quiver.edges:\n",
    "            quiver_rep_matrix_dict[e] = self.matrices[self.edge_tup_to_str(e)].weight.detach().cpu().numpy()\n",
    "        return quiver_rep(self.quiver, self.dims, quiver_rep_matrix_dict)\n",
    "    \n",
    "    def export_reduced_weights(self) -> quiver_rep:\n",
    "        exported_rep = self.export_weights()\n",
    "        return exported_rep.reduced_representation()\n",
    "    \n",
    "    def transformed_network(self):\n",
    "        exported_rep = self.export_weights()\n",
    "        rep_transformed = exported_rep.transformed_representation()\n",
    "        net_trans = QuiverNN(self.eta, self.quiver, self.dims)\n",
    "        net_trans.set_weights(rep_transformed)\n",
    "        #net_trans.set_activation_biases(self.export_activation_biases())\n",
    "        return net_trans\n",
    "        \n",
    "    def reduced_network(self):\n",
    "        reduced_rep = self.export_reduced_weights()\n",
    "        net_reduced = QuiverNN(self.eta, self.quiver, reduced_rep.dims)\n",
    "        net_reduced.set_weights(reduced_rep)\n",
    "        #net_trans.set_activation_biases(self.export_activation_biases())\n",
    "        return net_reduced\n",
    "    \n",
    "    \n",
    "    # Might not need these:\n",
    "    def export_activation_biases(self) -> List[float]:\n",
    "        None\n",
    "    def set_activation_biases(self, new_biases: List[float]):    \n",
    "        None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T03:51:56.274217Z",
     "start_time": "2022-03-10T03:51:56.262193Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bias': 1, 'a': 1, 'b': 2, 'c': 4, 'd': 2, 'e': 6}\n"
     ]
    }
   ],
   "source": [
    "vertex_list2 = ['a', 'b', 'c', 'd', 'e']\n",
    "edge_list2 = [('a', 'c'), ('b','c'), ('c','d'), ('c', 'e')]\n",
    "dim_vector2 = {'bias' : 1, 'a': 1, 'b': 2, 'c': 8, 'd': 2 , 'e': 6}\n",
    "quiv_ex2 = quiver(vertex_list2, edge_list2)\n",
    "quiv_ex2.add_bias()\n",
    "\n",
    "quiverNN = QuiverNN(eta = F.relu, quiver = quiv_ex2, dims = dim_vector2)\n",
    "\n",
    "# Representation of this quiver\n",
    "\n",
    "maps2 = {('a', 'c') : np.random.rand(8, 1), \n",
    "        ('b', 'c') : np.random.rand(8, 2), \n",
    "        ('c', 'd') : np.random.rand(2, 8),\n",
    "        ('c', 'e') : np.random.rand(6, 8),\n",
    "        ('bias', 'c') : np.random.rand(8, 1),\n",
    "        ('bias', 'd') : np.random.rand(2, 1),\n",
    "        ('bias', 'e') : np.random.rand(6, 1)}\n",
    "\n",
    "ex_rep2 = quiver_rep(quiv_ex2, dim_vector2, maps2)\n",
    "print(ex_rep2.comp_dims_red())\n",
    "\n",
    "quiverNN.set_weights(ex_rep2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T03:51:56.713198Z",
     "start_time": "2022-03-10T03:51:56.702475Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'d': tensor([[6.1138, 2.8710]], grad_fn=<MulBackward0>),\n",
       " 'e': tensor([[5.6408, 5.4776, 5.2808, 7.0878, 7.6400, 4.4642]],\n",
       "        grad_fn=<MulBackward0>)}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = {'a': torch.tensor([[1.0]]),'b': torch.tensor([[1.0,1.0]])}\n",
    "quiverNN(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T03:51:57.123123Z",
     "start_time": "2022-03-10T03:51:57.117508Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.quiver_rep at 0x7fa51abbfe80>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quiverNN.export_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T03:51:57.636298Z",
     "start_time": "2022-03-10T03:51:57.623200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.quiver_rep at 0x7fa51ab84340>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quiverNN.export_reduced_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T03:51:58.079049Z",
     "start_time": "2022-03-10T03:51:58.070921Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bias': 1, 'a': 1, 'b': 2, 'c': 4, 'd': 2, 'e': 6}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quiverNN.export_weights().comp_dims_red()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T03:51:58.710882Z",
     "start_time": "2022-03-10T03:51:58.689771Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuiverNN(\n",
       "  (matrices): ModuleDict(\n",
       "    (a to c): Linear(in_features=1, out_features=4, bias=False)\n",
       "    (b to c): Linear(in_features=2, out_features=4, bias=False)\n",
       "    (c to d): Linear(in_features=4, out_features=2, bias=False)\n",
       "    (c to e): Linear(in_features=4, out_features=6, bias=False)\n",
       "    (bias to c): Linear(in_features=1, out_features=4, bias=False)\n",
       "    (bias to d): Linear(in_features=1, out_features=2, bias=False)\n",
       "    (bias to e): Linear(in_features=1, out_features=6, bias=False)\n",
       "  )\n",
       "  (act): RadAct()\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_quiverNN = quiverNN.reduced_network()\n",
    "red_quiverNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T03:52:00.885534Z",
     "start_time": "2022-03-10T03:52:00.877440Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'d': tensor([[6.1138, 2.8710]], grad_fn=<MulBackward0>),\n",
       " 'e': tensor([[5.6408, 5.4776, 5.2808, 7.0878, 7.6400, 4.4642]],\n",
       "        grad_fn=<MulBackward0>)}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_quiverNN = quiverNN.reduced_network()\n",
    "x = {'a': torch.tensor([[1.0]]),'b': torch.tensor([[1.0,1.0]])}\n",
    "red_quiverNN(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Theorem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T04:23:20.109483Z",
     "start_time": "2022-03-10T04:23:20.097838Z"
    }
   },
   "outputs": [],
   "source": [
    "W = quiverNN.export_weights()\n",
    "T = quiverNN.transformed_network()\n",
    "Q,V = quiverNN.export_weights().QRDimRed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T04:23:20.562077Z",
     "start_time": "2022-03-10T04:23:20.545596Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bias': 1, 'a': 1, 'b': 2, 'c': 8, 'd': 2, 'e': 6}\n",
      "{'bias': 1, 'a': 1, 'b': 2, 'c': 4, 'd': 2, 'e': 6}\n",
      "\n",
      "('a', 'c')\n",
      "[[-1.63]\n",
      " [ 0.  ]\n",
      " [-0.  ]\n",
      " [-0.  ]\n",
      " [-0.  ]\n",
      " [ 0.  ]\n",
      " [-0.  ]\n",
      " [ 0.  ]]\n",
      "\n",
      "('b', 'c')\n",
      "[[-1.35 -1.3 ]\n",
      " [ 0.91  0.58]\n",
      " [ 0.   -0.68]\n",
      " [ 0.    0.  ]\n",
      " [-0.    0.  ]\n",
      " [ 0.    0.  ]\n",
      " [-0.   -0.  ]\n",
      " [ 0.    0.  ]]\n",
      "\n",
      "('c', 'd')\n",
      "[[-1.2   0.48 -0.37  0.04  0.74 -0.08  0.23  0.16]\n",
      " [-0.6   0.13 -0.15  0.49  0.2  -0.35  0.35  0.35]]\n",
      "\n",
      "('c', 'e')\n",
      "[[-1.22  0.09 -0.42 -0.05 -0.21 -0.12  0.47 -0.43]\n",
      " [-1.36 -0.28 -0.11  0.46  0.59  0.2   0.84 -0.19]\n",
      " [-1.17  0.18 -0.01  0.19  0.62 -0.23  0.52  0.06]\n",
      " [-1.56  0.03 -0.52  0.58 -0.04 -0.03 -0.   -0.06]\n",
      " [-1.75 -0.05 -0.33  0.4   0.29  0.24  0.42  0.56]\n",
      " [-0.85  0.21 -0.72  0.18  0.24  0.17 -0.15 -0.3 ]]\n",
      "\n",
      "('bias', 'c')\n",
      "[[-0.93]\n",
      " [-0.11]\n",
      " [-0.12]\n",
      " [ 0.61]\n",
      " [ 0.  ]\n",
      " [ 0.  ]\n",
      " [-0.  ]\n",
      " [ 0.  ]]\n",
      "\n",
      "('bias', 'd')\n",
      "[[0.39]\n",
      " [0.96]]\n",
      "\n",
      "('bias', 'e')\n",
      "[[0.32]\n",
      " [0.84]\n",
      " [0.12]\n",
      " [1.  ]\n",
      " [0.19]\n",
      " [0.63]]\n"
     ]
    }
   ],
   "source": [
    "print(quiverNN.dims)\n",
    "print(quiverNN.export_reduced_weights().dims)\n",
    "for e in T.quiver.edges:\n",
    "    print()\n",
    "    print(e)\n",
    "    print(T.get_matrix(e).detach().cpu().numpy().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T04:23:21.079605Z",
     "start_time": "2022-03-10T04:23:21.072048Z"
    }
   },
   "outputs": [],
   "source": [
    "def single_mask(red_rows, red_cols, orig_rows, orig_cols):\n",
    "    assert red_rows <= orig_rows \n",
    "    assert red_cols <= orig_cols\n",
    "    mask = torch.ones((orig_rows, orig_cols))\n",
    "    for j in range(red_rows, orig_rows):\n",
    "        mask[j][:red_cols] = 0\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Question*: Is the ```L``` in the function below encoding the loss function?\n",
    "$$ L = \\frac{1}{N} \\sum_{i = 1}^{N} (y_i)^2$$\n",
    "I guess at a later stage we will add something like ```(y - y_pred)**2```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T04:23:21.688216Z",
     "start_time": "2022-03-10T04:23:21.680964Z"
    }
   },
   "outputs": [],
   "source": [
    "def gamma(model, x, lr):\n",
    "    \n",
    "    y = model(x)\n",
    "    \n",
    "    # IG: Is this the value of the loss function?\n",
    "    L = torch.tensor(0.0)\n",
    "    for k in y:\n",
    "        L += y[k].pow(2).mean()\n",
    "    L.backward()\n",
    "    \n",
    "    print(L)\n",
    "    \n",
    "    with torch.no_grad(): \n",
    "        for e in model.quiver.edges:\n",
    "            p = model.get_matrix(e)\n",
    "            p -= lr * p.grad\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T04:23:22.288060Z",
     "start_time": "2022-03-10T04:23:22.275271Z"
    }
   },
   "outputs": [],
   "source": [
    "def gammaPGD(model, x, lr):\n",
    "    \n",
    "    y = model(x)\n",
    "    \n",
    "    dims = model.dims \n",
    "    red_dims = model.export_reduced_weights().dims\n",
    "    \n",
    "    L = torch.tensor(0.0)\n",
    "    for k in y:\n",
    "        L += y[k].pow(2).mean()\n",
    "    L.backward()\n",
    "\n",
    "    print(L)\n",
    "    \n",
    "    with torch.no_grad(): \n",
    "        for e in model.quiver.edges:\n",
    "            p = model.get_matrix(e)\n",
    "            mask_grad = single_mask(red_dims[e[1]],red_dims[e[0]],dims[e[1]],dims[e[0]])\n",
    "            p -= lr * (mask_grad * p.grad)\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T04:23:23.012204Z",
     "start_time": "2022-03-10T04:23:22.992710Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gd_quiverNN = type(quiverNN)(quiverNN.eta, quiverNN.quiver, quiverNN.dims) # get a new instance\n",
    "gd_quiverNN.load_state_dict(quiverNN.state_dict())\n",
    "\n",
    "pgd_quiverNN = type(quiverNN)(quiverNN.eta, quiverNN.quiver, quiverNN.dims) # get a new instance\n",
    "pgd_quiverNN.load_state_dict(quiverNN.state_dict())\n",
    "\n",
    "gd_red_quiverNN = type(red_quiverNN)(red_quiverNN.eta, red_quiverNN.quiver, red_quiverNN.dims) # get a new instance\n",
    "gd_red_quiverNN.load_state_dict(red_quiverNN.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T04:23:23.856046Z",
     "start_time": "2022-03-10T04:23:23.848381Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pgd_T = type(T)(T.eta, T.quiver, T.dims) # get a new instance\n",
    "pgd_T.load_state_dict(T.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T04:23:24.668801Z",
     "start_time": "2022-03-10T04:23:24.663759Z"
    }
   },
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "x = {'a': torch.tensor([[1.0]]),'b': torch.tensor([[1.0,1.0]])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T16:02:33.464904Z",
     "start_time": "2022-03-10T16:02:33.458309Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(50.3316, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "gamma(gd_quiverNN, x, lr);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T16:02:44.983450Z",
     "start_time": "2022-03-10T16:02:44.977017Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(52.5662, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "gammaPGD(pgd_quiverNN, x, lr);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T16:02:45.753980Z",
     "start_time": "2022-03-10T16:02:45.748411Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(50.6135, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "gamma(gd_red_quiverNN, x, lr);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T16:02:46.369514Z",
     "start_time": "2022-03-10T16:02:46.363414Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(50.6135, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "gammaPGD(pgd_T, x, lr);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gamma(W) = Q gamma(T)\n",
    "# gammaP(T) - T = ( gamma(V) -V )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T04:24:32.049651Z",
     "start_time": "2022-03-10T04:24:32.044653Z"
    }
   },
   "outputs": [],
   "source": [
    "# ToDo: Add Q action on network\n",
    "# Add padding function for comparison "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T04:28:14.191343Z",
     "start_time": "2022-03-01T04:28:14.162307Z"
    }
   },
   "outputs": [],
   "source": [
    "#################################\n",
    "## Loss function (mean square error)\n",
    "#################################\n",
    "\n",
    "def loss_fn(y_predict, y_train):\n",
    "    squared_diffs = (y_predict - y_train)**2\n",
    "    return squared_diffs.mean()\n",
    "\n",
    "\n",
    "#################################\n",
    "## Masks used in projected gradient descent\n",
    "#################################\n",
    "\n",
    "def single_mask(red_rows, red_cols, orig_rows, orig_cols):\n",
    "    assert red_rows <= orig_rows \n",
    "    assert red_cols <= orig_cols\n",
    "    mask = torch.ones((orig_rows, orig_cols))\n",
    "    for j in range(red_rows, orig_rows):\n",
    "        mask[j][:red_cols] = 0\n",
    "    return mask\n",
    "\n",
    "def masks(reduced_dims, orig_dims):\n",
    "    N = len(reduced_dims)\n",
    "    assert N == len(orig_dims), \\\n",
    "    \"Lengths must match\"\n",
    "    assert all([reduced_dims[i] <= orig_dims[i] for i in range(N)]), \\\n",
    "        \"Reduced dimension vector must not be larger in any coordinate\"\n",
    "    \n",
    "    masks = []\n",
    "    \n",
    "    # Add masks in order corresponding to the parameters\n",
    "    for i in range(N-1):\n",
    "        masks.append(single_mask(reduced_dims[i+1], reduced_dims[i], orig_dims[i+1], orig_dims[i]))\n",
    "        masks.append(torch.transpose(single_mask(reduced_dims[i+1], 1, orig_dims[i+1],1 ), 0,1).reshape(orig_dims[i+1]))\n",
    "    \n",
    "    return(masks)\n",
    "\n",
    "\n",
    "#################################\n",
    "## Training loop with usual gradient descent\n",
    "## Optimizer excluded to remove randomness\n",
    "#################################\n",
    "\n",
    "def training_loop(n_epochs, learning_rate, model, params, x_train, y_train, verbose=True):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        for p in params:\n",
    " \n",
    "          if p.grad is not None: \n",
    "                p.grad.zero_()\n",
    "        \n",
    "        y_pred = model(x_train) \n",
    "        loss = loss_fn(y_pred, y_train)            \n",
    "        loss.backward()\n",
    "        \n",
    "        with torch.no_grad(): \n",
    "            for p in params:\n",
    "                p -= learning_rate * p.grad\n",
    "                \n",
    "        if verbose:\n",
    "            if epoch ==1 or epoch % 500 == 0:\n",
    "                print('Epoch %d, Loss %f' % (epoch, float(loss)))\n",
    "            \n",
    "    return model\n",
    "\n",
    "\n",
    "#################################\n",
    "## Training loop with projected gradient descent\n",
    "## Optimizer excluded to remove randomness\n",
    "#################################\n",
    "\n",
    "def training_loop_proj_GD(n_epochs, learning_rate, model, params, original_dimensions, reduced_dimensions, \\\n",
    "                          x_train, y_train, verbose=True):\n",
    "    \n",
    "    param_masks = masks(reduced_dimensions, original_dimensions)\n",
    "    \n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        for p in params:\n",
    "            if p.grad is not None: \n",
    "                p.grad.zero_()\n",
    "        \n",
    "        y_pred = model(x_train) \n",
    "        loss = loss_fn(y_pred, y_train)            \n",
    "        loss.backward()\n",
    "        \n",
    "        with torch.no_grad(): \n",
    "            for p,m in zip(params, param_masks):\n",
    "                assert p.shape == m.shape, \"Parameter shape and mask shape don't match\"\n",
    "                \n",
    "                # Use the mask to zero out gradients that will not be updated\n",
    "                p -= learning_rate * (p.grad * m)\n",
    "                \n",
    "        if verbose:\n",
    "            if epoch ==1 or epoch % 500 == 0:\n",
    "                print('Epoch %d, Loss %f' % (epoch, float(loss)))\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T19:15:45.683291Z",
     "start_time": "2022-02-18T19:15:44.729Z"
    }
   },
   "outputs": [],
   "source": [
    "class vertex:\n",
    "    def __init__(self):\n",
    "        None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T19:15:45.683918Z",
     "start_time": "2022-02-18T19:15:44.730Z"
    }
   },
   "outputs": [],
   "source": [
    "a = vertex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T19:15:45.684576Z",
     "start_time": "2022-02-18T19:15:44.734Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Troubleshooting\n",
    "\n",
    "W1 = np.random.rand(4, 2)\n",
    "print(type(W1))\n",
    "print(isinstance(W1, np.ndarray))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T19:15:45.685171Z",
     "start_time": "2022-02-18T19:15:44.737Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.81281339, 0.49915742],\n",
       "        [0.26955573, 0.30086518],\n",
       "        [0.71580727, 0.68932149],\n",
       "        [0.53062664, 0.44406173]]),\n",
       " array([[0.80727751, 0.72668535, 0.92962125, 0.56415121],\n",
       "        [0.34216681, 0.5939487 , 0.73583019, 0.38777651],\n",
       "        [0.34086441, 0.13768551, 0.71729477, 0.50002675],\n",
       "        [0.81179308, 0.97525958, 0.84721144, 0.39236812]]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.random.rand(4,2)\n",
    "b = np.random.rand(4,4)\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T19:15:45.685709Z",
     "start_time": "2022-02-18T19:15:44.737Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 6)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = np.hstack((a,b))\n",
    "np.shape(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T19:15:45.686275Z",
     "start_time": "2022-02-18T19:15:44.739Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.80727751, 0.72668535, 0.92962125, 0.56415121],\n",
       "       [0.34216681, 0.5939487 , 0.73583019, 0.38777651],\n",
       "       [0.34086441, 0.13768551, 0.71729477, 0.50002675],\n",
       "       [0.81179308, 0.97525958, 0.84721144, 0.39236812]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T19:15:45.686990Z",
     "start_time": "2022-02-18T19:15:44.740Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.80727751, 0.72668535],\n",
       "       [0.34216681, 0.5939487 ],\n",
       "       [0.34086441, 0.13768551],\n",
       "       [0.81179308, 0.97525958]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[:,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T19:15:45.687633Z",
     "start_time": "2022-02-18T19:15:44.741Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.92962125, 0.56415121],\n",
       "       [0.73583019, 0.38777651],\n",
       "       [0.71729477, 0.50002675],\n",
       "       [0.84721144, 0.39236812]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T19:15:45.688326Z",
     "start_time": "2022-02-18T19:15:44.743Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 2)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(b[:,:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T19:15:45.689007Z",
     "start_time": "2022-02-18T19:15:44.744Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(np.array([]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T12:58:12.661152Z",
     "start_time": "2022-03-01T12:58:12.642219Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tensor() got an unexpected keyword argument 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-af1b9ec111c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"a to b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: tensor() got an unexpected keyword argument 'name'"
     ]
    }
   ],
   "source": [
    "torch.nn.Parameter(torch.tensor([[1.0]],dtype = torch.float,name=\"a to b\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
