{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T03:17:36.604915Z",
     "start_time": "2022-03-01T03:17:33.589302Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: cpu\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Dict, Tuple\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "dev = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    dev = 'cuda:0'\n",
    "print(\"Running on:\",dev)\n",
    "device = torch.device(dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quivers and quiver representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quiver class is designed to define an acyclic quiver with no double edges. The initial quiver is not required to have a bias vertex; such a vertex can be added with the ```add_bias()``` method.\n",
    "\n",
    "The input list of vertices is meant to be a list of strings, one for each vertex. It is best to avoid the label ```bias``` among the vertices. \n",
    "\n",
    "The input list of edges is meant to be a tuple ```e = (e[0], e[1])``` where ```e[0]``` is the source and ```e[1]``` is the target. No double edges or loops are allowed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T03:17:38.417391Z",
     "start_time": "2022-03-01T03:17:38.409947Z"
    }
   },
   "outputs": [],
   "source": [
    "class quiver:\n",
    "    \"\"\"Quiver class. Vertices are given as a list of strings. Edges are given as a list of pairs.\n",
    "    \n",
    "    Attributes and Methods.\n",
    "    \"\"\"\n",
    "    def __init__(self, vertices : List[str], edges : List[Tuple[str]]):\n",
    "        self.vertices = vertices\n",
    "        # Add assert to check no repeated vertices\n",
    "        # E.g. assert len(set(vertices)) == len(vertices)\n",
    "        # Assert there is no bias initially, or if there is, it has the desired properties\n",
    "        \n",
    "        self.edges = edges\n",
    "        # Add assert to check that edges is a list of pairs\n",
    "        # First entry of the pair is the sourse, second is the target\n",
    "        # Source and target of each edge should be in the vertex set      \n",
    "        # Separate class for edges? vertices?\n",
    "        \n",
    "        # Get the sources and sinks\n",
    "        sources = set(self.vertices)\n",
    "        sinks = set(self.vertices)\n",
    "        for e in self.edges:\n",
    "            sources.discard(e[1])\n",
    "            sinks.discard(e[0])\n",
    "        self.sources = sources\n",
    "        self.sinks = sinks\n",
    "    \n",
    "    # Check that the quiver is acyclic\n",
    "    def check_acyclic(self):\n",
    "        None\n",
    "        # One way: find all sources, do depth-first search\n",
    "        \n",
    "    # Check that the vertices are in topological order    \n",
    "    def check_top_order(self):\n",
    "        indices = {}\n",
    "        for i,v in enumerate(self.vertices):\n",
    "            indices[v] = i\n",
    "        return all([indices[e[0]] <  indices[e[1]] for e in self.edges])\n",
    "        \n",
    "    # Get the incoming edges for every vertex\n",
    "    def get_incoming(self, vertex):\n",
    "        assert vertex in self.vertices, \"No such vertex found\"\n",
    "        return [e for e in self.edges if e[1] == vertex]\n",
    "        # Can get the incoming neighbors as [e[1] for e in self.get_incoming(vertex)]\n",
    "        \n",
    "    # Add a bias vertex. Considering alternatives to this ... \n",
    "    def add_bias(self):\n",
    "        # Add bias vertex. This will not disturb the topological order.\n",
    "        for v in self.vertices:\n",
    "            if v not in self.sources:\n",
    "                self.edges.append(('bias', v))\n",
    "        self.vertices = ['bias'] + self.vertices\n",
    "        return\n",
    "    \n",
    "    ######\n",
    "    # Check if a vertex is a sink (Don't really need this any more)\n",
    "    def is_sink(self, vertex):\n",
    "        assert vertex in self.vertices, \"No such vertex found\"\n",
    "        return all([e[0] != vertex for e in self.edges])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T03:17:39.158799Z",
     "start_time": "2022-03-01T03:17:39.124758Z"
    }
   },
   "outputs": [],
   "source": [
    "class quiver_rep:\n",
    "    \"\"\"Quiver representation class. Input a quiver with dimension vector and a matrix for each edge.\"\"\"\n",
    "    def __init__(self, quiver: quiver, dims: Dict[str,int], matrices: Dict[str, np.array]):\n",
    "        self.quiver = quiver\n",
    "        self.dims = dims\n",
    "        self.matrices = matrices\n",
    "        \n",
    "        # Check the dimension vector\n",
    "        assert len(dims) == len(self.quiver.vertices), \"Inappropriate dimension vector\"\n",
    "        for v in dims:\n",
    "            assert v in self.quiver.vertices, \"Inappropriate dim vector\"\n",
    "            assert isinstance(dims[v], int) and dims[v] >=0, \"Dimension needs to be a positive integer\"\n",
    "        assert dims['bias'] == 1, \"Dimension at bias needs to be 1\"\n",
    "\n",
    "            \n",
    "        # Check the matrices\n",
    "        assert len(matrices) == len(self.quiver.edges), \"Matrices error\"\n",
    "        for e in matrices:\n",
    "            assert e in self.quiver.edges, \"Matrices error\"\n",
    "            assert isinstance(matrices[e], np.ndarray), \"Matrices error\" # May need fixing\n",
    "            assert np.shape(matrices[e]) == (dims[e[1]], dims[e[0]]), \"Dimension error\"\n",
    "            \n",
    "            \n",
    "    # Compute the reduced dimension vector\n",
    "    def comp_dims_red(self) -> Dict:\n",
    "        \n",
    "        assert self.quiver.check_top_order(), \"Order of the vertices is not topological\"\n",
    "\n",
    "        dims_red = {}\n",
    "        for i in self.quiver.vertices:\n",
    "            if i == 'bias' or i in self.quiver.sources or i in self.quiver.sinks:\n",
    "                dims_red[i] = self.dims[i]\n",
    "            else:\n",
    "                incoming = self.quiver.get_incoming(i)\n",
    "                dims_red[i] = min(self.dims[i], sum([dims_red[e[0]] for e in incoming]) )\n",
    "\n",
    "                    \n",
    "        self.dims_red = dims_red        \n",
    "        return dims_red\n",
    "    \n",
    "    \n",
    "    # Auxiliary function\n",
    "    def padzeros(self, M, newrows, newcols = None):\n",
    "        oldrows, oldcols = M.shape\n",
    "        if newcols == None:\n",
    "            newcols = oldcols\n",
    "        return np.pad(M,((0,newrows-oldrows),(0,newcols-oldcols)),mode=\"constant\")\n",
    " \n",
    "    \n",
    "    # QR dimensional reduction algorithm\n",
    "    def QRDimRed(self, verbose : bool = False ):\n",
    "        dims = self.dims\n",
    "        matrices = self.matrices\n",
    "        quiver = self.quiver\n",
    "        vertices = quiver.vertices\n",
    "        edges = quiver.edges\n",
    "\n",
    "        # Check that vertices are in a topological order\n",
    "        assert quiver.check_top_order(), \"Order of the vertices is not topological\"\n",
    "\n",
    "        # Compute the reduced dimension vector\n",
    "        dims_red = self.comp_dims_red()\n",
    "        # print(dims, dims_red)\n",
    "\n",
    "        # Q = dictionary mapping each vertex to an orthogonal matrix\n",
    "        Q = {}\n",
    "\n",
    "        # Vmatrices = matrices of the reduced representation V, mapping each edge to a matrix\n",
    "        Vmatrices = {}\n",
    "\n",
    "        if verbose:\n",
    "            print(quiver.edges)\n",
    "            print(quiver.vertices)\n",
    "\n",
    "        for i in vertices:\n",
    "            incoming = quiver.get_incoming(i)\n",
    "\n",
    "            # Case of a source vertex\n",
    "            if incoming == []:\n",
    "                Q[i] = np.eye(dims[i])\n",
    "\n",
    "            # Case of a hidden vertex    \n",
    "            elif i not in quiver.sinks:\n",
    "\n",
    "                # Compute the matrix to be QR-decomposed\n",
    "                M = np.array([])\n",
    "                for e in incoming:\n",
    "                    # Transform weights on incoming edges\n",
    "                    Qj = Q[e[0]]\n",
    "                    Me = matrices[e] @ Qj[:,:dims_red[e[0]]]\n",
    "                    if np.shape(M) == (0,):\n",
    "                        M = Me\n",
    "                    else:\n",
    "                        M = np.hstack((M, Me))\n",
    "\n",
    "                Q[i], R = np.linalg.qr(M, mode=\"complete\")\n",
    "\n",
    "                # Case of reduction \n",
    "                if dims_red[i] < dims[i]: \n",
    "                    R = R[:dims_red[i]]\n",
    "\n",
    "                # Process and add to the dictionaries\n",
    "                for e in incoming:                       \n",
    "                    # Extract V_e from R_i for all incoming edges e\n",
    "                    Vmatrices[e] = R[:,:dims_red[e[0]]]\n",
    "                    R = R[:,dims_red[e[0]]:]\n",
    "\n",
    "            # Case of a sink (no reduction)\n",
    "            else:\n",
    "                Q[i] = np.eye(dims[i])\n",
    "                for e in incoming:\n",
    "                    # Transform weights on incoming edges\n",
    "                    Qj = Q[e[0]]\n",
    "                    Vmatrices[e] = matrices[e] @ Qj[:,:dims_red[e[0]]]                \n",
    "\n",
    "\n",
    "        # Make V into a representation\n",
    "        V = quiver_rep(quiver, dims_red, Vmatrices)\n",
    "\n",
    "        # Verify that V is a subrepresentation of Q^{-1} W  \n",
    "        for e in quiver.edges:\n",
    "            Qi = Q[e[0]]\n",
    "            Qj = Q[e[1]]\n",
    "            max_diff = np.max(np.abs(np.transpose(Qj) @ matrices[e] @ Qi[:,:dims_red[e[0]]] \n",
    "                         - self.padzeros(Vmatrices[e], dims[e[1]])))\n",
    "            assert max_diff < 1e-10, \"Error in the algorithm\"\n",
    "\n",
    "        return Q, V\n",
    "    \n",
    "    \n",
    "    def reduced_representation(self, verbose : bool = False ):\n",
    "        return self.QRDimRed(verbose)[1]\n",
    "                \n",
    "    def transformed_representation(self):\n",
    "        Q, V = self.QRDimRed()\n",
    "        transformed_mat_dict = {}\n",
    "        for e in self.quiver.edges:\n",
    "            transformed_mat_dict[e] = np.transpose(Q[e[1]]) @ self.matrices[e] @ Q[e[0]]\n",
    "        \n",
    "        Q_inv_W = quiver_rep(self.quiver, self.dims, transformed_mat_dict)\n",
    "        \n",
    "        return Q_inv_W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T00:41:27.213007Z",
     "start_time": "2022-03-01T00:41:27.206820Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "### Linear Feedforward Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T00:40:52.573895Z",
     "start_time": "2022-03-01T00:40:02.394Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Linear feedforward function, ignoring biases\n",
    "# Might turn out not to be super necessary\n",
    "\n",
    "def lin_ff(W : quiver_rep) -> np.array:\n",
    "    dims = W.dims\n",
    "    matrices = W.matrices\n",
    "    quiver = W.quiver\n",
    "    vertices = quiver.vertices\n",
    "    edges = quiver.edges\n",
    "    \n",
    "    assert quiver.check_top_order(), \"Order of the vertices is not topological\"\n",
    "    \n",
    "    # Dictionary for partial feedforward functions:\n",
    "    partial = {}\n",
    "    input_dim = 0\n",
    "    # input_dim = sum( [dims[i] for i in quiver.sources])\n",
    "    \n",
    "    for i in quiver.vertices:\n",
    "        incoming = quiver.get_incoming(i)\n",
    "        \n",
    "        # Case of a source\n",
    "        if i in quiver.sources:\n",
    "            \n",
    "            # Update matrices already defined\n",
    "            for j in partial:\n",
    "                partial[j] = np.hstack((partial[j], np.zeros((dims[j],dims[i]))))\n",
    "                \n",
    "            # Define the new matrix as a projection matrix\n",
    "            if input_dim == 0:\n",
    "                partial[i] = np.eye(dims[i])\n",
    "            else:\n",
    "                partial[i] = np.hstack((np.zeros((dims[i], input_dim)), np.eye(dims[i])))\n",
    "            input_dim += dims[i]\n",
    "\n",
    "        # Case of a hidden vertex or a sink\n",
    "        else:\n",
    "            \n",
    "            # Compute the matrix to be added\n",
    "            A = np.zeros((dims[i], input_dim))\n",
    "            for e in incoming:\n",
    "                # Ignore biases for now\n",
    "                if e[0] != 'bias':\n",
    "                    A += matrices[e] @ partial[e[0]]\n",
    "            partial[i] = A\n",
    "         \n",
    "    # Compute the final output matrix by stacking the matrices for sinks\n",
    "    result = np.array([])\n",
    "    for i in quiver.sinks:\n",
    "        if np.shape(result) == (0,):\n",
    "            result = partial[i]\n",
    "        else:\n",
    "            result = np.vstack((result, partial[i]))\n",
    "                        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Dimensional reduction algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T23:38:55.822031Z",
     "start_time": "2022-02-28T23:38:55.807678Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Auxiliary function\n",
    "\n",
    "def padzeros(M,newrows,newcols = None):\n",
    "    oldrows, oldcols = M.shape\n",
    "    if newcols == None:\n",
    "        newcols = oldcols\n",
    "    return np.pad(M,((0,newrows-oldrows),(0,newcols-oldcols)),mode=\"constant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T23:38:56.170953Z",
     "start_time": "2022-02-28T23:38:56.150814Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# QR dimensional reduction algorithm\n",
    "# This is incorporated in the quiver_rep class\n",
    "\n",
    "def QRDimRed(W : quiver_rep, verbose : bool = False ):\n",
    "    dims = W.dims\n",
    "    matrices = W.matrices\n",
    "    quiver = W.quiver\n",
    "    vertices = quiver.vertices\n",
    "    edges = quiver.edges\n",
    "    \n",
    "    # Check that vertices are in a topological order\n",
    "    assert quiver.check_top_order(), \"Order of the vertices is not topological\"\n",
    "    \n",
    "    # Compute the reduced dimension vector\n",
    "    dims_red = W.comp_dims_red()\n",
    "    # print(dims, dims_red)\n",
    "    \n",
    "    # Q = dictionary mapping each vertex to an orthogonal matrix\n",
    "    Q = {}\n",
    "    \n",
    "    # Vmatrices = matrices of the reduced representation V, mapping each edge to a matrix\n",
    "    Vmatrices = {}\n",
    "    \n",
    "    if verbose:\n",
    "        print(quiver.edges)\n",
    "        print(quiver.vertices)\n",
    "    \n",
    "    for i in vertices:\n",
    "        incoming = quiver.get_incoming(i)\n",
    "        \n",
    "        # Case of a source vertex\n",
    "        if incoming == []:\n",
    "            Q[i] = np.eye(dims[i])\n",
    "            \n",
    "        # Case of a hidden vertex    \n",
    "        elif i not in quiver.sinks:\n",
    "            \n",
    "            # Compute the matrix to be QR-decomposed\n",
    "            M = np.array([])\n",
    "            for e in incoming:\n",
    "                # Transform weights on incoming edges\n",
    "                Qj = Q[e[0]]\n",
    "                Me = matrices[e] @ Qj[:,:dims_red[e[0]]]\n",
    "                if np.shape(M) == (0,):\n",
    "                    M = Me\n",
    "                else:\n",
    "                    M = np.hstack((M, Me))\n",
    "                    \n",
    "            Q[i], R = np.linalg.qr(M, mode=\"complete\")\n",
    "\n",
    "            # Case of reduction \n",
    "            if dims_red[i] < dims[i]: \n",
    "                R = R[:dims_red[i]]\n",
    "                \n",
    "            # Process and add to the dictionaries\n",
    "            for e in incoming:                       \n",
    "                # Extract V_e from R_i for all incoming edges e\n",
    "                Vmatrices[e] = R[:,:dims_red[e[0]]]\n",
    "                R = R[:,dims_red[e[0]]:]\n",
    "                \n",
    "        # Case of a sink (no reduction)\n",
    "        else:\n",
    "            Q[i] = np.eye(dims[i])\n",
    "            for e in incoming:\n",
    "                # Transform weights on incoming edges\n",
    "                Qj = Q[e[0]]\n",
    "                Vmatrices[e] = matrices[e] @ Qj[:,:dims_red[e[0]]]                \n",
    "\n",
    "    \n",
    "    # Make V into a representation\n",
    "    V = quiver_rep(quiver, dims_red, Vmatrices)\n",
    "\n",
    "    # Verify that V is a subrepresentation of Q^{-1} W  \n",
    "    for e in quiver.edges:\n",
    "        Qi = Q[e[0]]\n",
    "        Qj = Q[e[1]]\n",
    "        max_diff = np.max(np.abs(np.transpose(Qj) @ matrices[e] @ Qi[:,:dims_red[e[0]]] \n",
    "                     - padzeros(Vmatrices[e], dims[e[1]])))\n",
    "        assert max_diff < 1e-10, \"Error in the algorithm\"\n",
    "\n",
    "    return Q, V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T23:33:36.074709Z",
     "start_time": "2022-02-28T23:33:36.058387Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [('a', 'b')] [('a', 'c'), ('b', 'c')] [('c', 'd')]\n",
      "False False False True\n",
      "True\n",
      "{'a'}\n",
      "['bias', 'a', 'b', 'c', 'd']\n",
      "[('a', 'b'), ('a', 'c'), ('b', 'c'), ('c', 'd'), ('bias', 'b'), ('bias', 'c'), ('bias', 'd')]\n"
     ]
    }
   ],
   "source": [
    "# EXAMPLE\n",
    "# Quiver with skip connections and no bias\n",
    "\n",
    "vertex_list = ['a', 'b', 'c', 'd']\n",
    "edge_list = [('a', 'b'), ('a','c'), ('b','c'), ('c', 'd')]\n",
    "\n",
    "quiv_ex = quiver(vertex_list, edge_list)\n",
    "# print(Q.vertices, Q.edges)\n",
    "\n",
    "# Test the methods\n",
    "print(quiv_ex.get_incoming('a'), quiv_ex.get_incoming('b'), quiv_ex.get_incoming('c'), quiv_ex.get_incoming('d'))\n",
    "print(quiv_ex.is_sink('a'), quiv_ex.is_sink('b'), quiv_ex.is_sink('c'), quiv_ex.is_sink('d'))\n",
    "print(quiv_ex.check_top_order())\n",
    "print(quiv_ex.sources)\n",
    "quiv_ex.add_bias()\n",
    "print(quiv_ex.vertices)\n",
    "print(quiv_ex.edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T22:34:00.796644Z",
     "start_time": "2022-02-28T22:34:00.791668Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bias': 1, 'a': 2, 'b': 3, 'c': 6, 'd': 2}\n"
     ]
    }
   ],
   "source": [
    "# Representation of this quiver\n",
    "\n",
    "dim_vector = {'bias' : 1, 'a': 2, 'b': 4, 'c': 8, 'd': 2 }\n",
    "\n",
    "maps = {('a', 'b') : np.random.rand(4, 2), \n",
    "        ('a', 'c') : np.random.rand(8, 2), \n",
    "        ('b', 'c') : np.random.rand(8, 4),\n",
    "        ('c', 'd') : np.random.rand(2, 8),\n",
    "        ('bias', 'b') : np.random.rand(4, 1),\n",
    "        ('bias', 'c') : np.random.rand(8, 1),\n",
    "        ('bias', 'd') : np.random.rand(2, 1)}\n",
    "\n",
    "ex_rep = quiver_rep(quiv_ex, dim_vector, maps)\n",
    "print(ex_rep.comp_dims_red())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T22:34:00.979180Z",
     "start_time": "2022-02-28T22:34:00.943775Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bias': 1, 'a': 2, 'b': 3, 'c': 6, 'd': 2}\n",
      "[(1, 1), (2, 2), (4, 4), (8, 8), (2, 2)]\n",
      "[(3, 2), (3, 1), (6, 2), (6, 3), (6, 1), (2, 6), (2, 1)]\n"
     ]
    }
   ],
   "source": [
    "# Check the algorithm\n",
    "\n",
    "Q_ex ,V_ex = QRDimRed(ex_rep)\n",
    "print(ex_rep.comp_dims_red())\n",
    "print([np.shape(Q_ex[i]) for i in Q_ex])\n",
    "print([np.shape(V_ex.matrices[e]) for e in V_ex.matrices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T22:34:01.100807Z",
     "start_time": "2022-02-28T22:34:01.095091Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.84656088, 7.27676386],\n",
       "       [6.16817118, 5.87194995]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_ff(ex_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T22:34:01.272463Z",
     "start_time": "2022-02-28T22:34:01.260708Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.84656088, 7.27676386],\n",
       "       [6.16817118, 5.87194995]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_rep.matrices[('c','d')] @ ( ex_rep.matrices[('a','c')] + ex_rep.matrices[('b','c')] @ ex_rep.matrices[('a','b')] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T22:34:01.409739Z",
     "start_time": "2022-02-28T22:34:01.402851Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.84656088, 7.27676386],\n",
       "       [6.16817118, 5.87194995]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_ff(V_ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T03:17:58.426276Z",
     "start_time": "2022-03-01T03:17:58.414445Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [] [('a', 'c'), ('b', 'c')] [('c', 'd')] [('c', 'e')]\n",
      "False False False True True\n",
      "True\n",
      "{'b', 'a'}\n",
      "['bias', 'a', 'b', 'c', 'd', 'e']\n",
      "[('a', 'c'), ('b', 'c'), ('c', 'd'), ('c', 'e'), ('bias', 'c'), ('bias', 'd'), ('bias', 'e')]\n"
     ]
    }
   ],
   "source": [
    "# EXAMPLE\n",
    "# Quiver with multiple inputs and outputs\n",
    "\n",
    "vertex_list2 = ['a', 'b', 'c', 'd', 'e']\n",
    "edge_list2 = [('a', 'c'), ('b','c'), ('c','d'), ('c', 'e')]\n",
    "\n",
    "quiv_ex2 = quiver(vertex_list2, edge_list2)\n",
    "# print(Q.vertices, Q.edges)\n",
    "\n",
    "# Test the methods\n",
    "print(quiv_ex2.get_incoming('a'), quiv_ex2.get_incoming('b'), quiv_ex2.get_incoming('c'), \n",
    "      quiv_ex2.get_incoming('d'), quiv_ex2.get_incoming('e'))\n",
    "print(quiv_ex2.is_sink('a'), quiv_ex2.is_sink('b'), quiv_ex2.is_sink('c'), \n",
    "      quiv_ex2.is_sink('d'), quiv_ex2.is_sink('e'))\n",
    "print(quiv_ex2.check_top_order())\n",
    "print(quiv_ex2.sources)\n",
    "quiv_ex2.add_bias()\n",
    "print(quiv_ex2.vertices)\n",
    "print(quiv_ex2.edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T03:18:07.067885Z",
     "start_time": "2022-03-01T03:18:07.054127Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bias': 1, 'a': 1, 'b': 2, 'c': 4, 'd': 2, 'e': 6}\n"
     ]
    }
   ],
   "source": [
    "# Representation of this quiver\n",
    "\n",
    "dim_vector2 = {'bias' : 1, 'a': 1, 'b': 2, 'c': 8, 'd': 2 , 'e': 6}\n",
    "\n",
    "maps2 = {('a', 'c') : np.random.rand(8, 1), \n",
    "        ('b', 'c') : np.random.rand(8, 2), \n",
    "        ('c', 'd') : np.random.rand(2, 8),\n",
    "        ('c', 'e') : np.random.rand(6, 8),\n",
    "        ('bias', 'c') : np.random.rand(8, 1),\n",
    "        ('bias', 'd') : np.random.rand(2, 1),\n",
    "        ('bias', 'e') : np.random.rand(6, 1)}\n",
    "\n",
    "ex_rep2 = quiver_rep(quiv_ex2, dim_vector2, maps2)\n",
    "print(ex_rep2.comp_dims_red())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T03:18:07.442124Z",
     "start_time": "2022-03-01T03:18:07.432791Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'QRDimRed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-908bcd974687>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Check the algorithm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mQ_ex2\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mV_ex2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQRDimRed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex_rep2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex_rep2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomp_dims_red\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ_ex2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mQ_ex2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'QRDimRed' is not defined"
     ]
    }
   ],
   "source": [
    "# Check the algorithm\n",
    "\n",
    "Q_ex2 ,V_ex2 = QRDimRed(ex_rep2)\n",
    "print(ex_rep2.comp_dims_red())\n",
    "print([np.shape(Q_ex2[i]) for i in Q_ex2])\n",
    "print([np.shape(V_ex2.matrices[e]) for e in V_ex2.matrices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T03:18:07.876279Z",
     "start_time": "2022-03-01T03:18:07.865882Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lin_ff' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-e99f8a682bfb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlin_ff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex_rep2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'lin_ff' is not defined"
     ]
    }
   ],
   "source": [
    "lin_ff(ex_rep2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T03:18:10.255026Z",
     "start_time": "2022-03-01T03:18:10.248834Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lin_ff' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-68c59a4dfe10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlin_ff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV_ex2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'lin_ff' is not defined"
     ]
    }
   ],
   "source": [
    "lin_ff(V_ex2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiver Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T04:30:23.767143Z",
     "start_time": "2022-03-01T04:30:23.759042Z"
    }
   },
   "outputs": [],
   "source": [
    "class RadAct(nn.Module):\n",
    "    def __init__(self, eta = F.relu):\n",
    "        super().__init__()\n",
    "        self.eta = eta\n",
    "        self.shift = 0 \n",
    "        # Add internal bias/shift later\n",
    "        \n",
    "    def forward(self,x):\n",
    "        # x: [Batch x Channel]\n",
    "        # Radial activations\n",
    "        r = torch.linalg.norm(x, dim=-1) \n",
    "        if torch.min(r) < 1e-6:\n",
    "            r += 1e-6\n",
    "        scalar = self.eta(r + self.shift) / r\n",
    "        return x * scalar.unsqueeze(-1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T14:16:49.020556Z",
     "start_time": "2022-03-01T14:16:49.008381Z"
    }
   },
   "outputs": [],
   "source": [
    "class QuiverNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, eta: float , quiver: quiver, dims: Dict[str,int] ):\n",
    "        super().__init__()\n",
    "        self.eta = eta\n",
    "        self.quiver = quiver\n",
    "        self.dims = dims\n",
    "        self.matrices = nn.ModuleDict()\n",
    "        for e in quiver.edges:\n",
    "            self.matrices[self.edge_tup_to_str(e)] = nn.Linear(self.dims[e[0]], self.dims[e[1]], bias = False)\n",
    "        \n",
    "        assert quiver.check_top_order(), \"Vertices not in topological order.\"\n",
    "        \n",
    "        self.act = RadAct(self.eta)\n",
    "        #self.quiver_rep = quiver_rep()\n",
    "        \n",
    "        # Assert statement to check that dims is a dimension vector for Q\n",
    "        \n",
    "        # Reduced dimension vector\n",
    "    \n",
    "    def edge_tup_to_str(self,e):\n",
    "        (t,h) = e\n",
    "        return t + \" to \" + h\n",
    "    \n",
    "    def get_matrix(self,e):\n",
    "        return self.matrices[self.edge_tup_to_str(e)].weight\n",
    "\n",
    "    def edge_str_to_tup(self,e):\n",
    "        t,to,h = e.split()\n",
    "        return (t,h)\n",
    "\n",
    "    def forward(self, x, non_linear = True):\n",
    "        \n",
    "        #Initialize Data Flow\n",
    "        h = {}\n",
    "        h['bias'] = torch.tensor(1.0)\n",
    "        for v in self.quiver.sources:\n",
    "            h[v] = x[v]\n",
    "            batch_size = x[v].shape[0]\n",
    "        \n",
    "        #Assert batchsize is same for all sources \n",
    "        \n",
    "        for v in self.quiver.vertices:\n",
    "            if v not in self.quiver.sources:\n",
    "                h[v] = torch.zeros(batch_size,self.dims[v])\n",
    "                for e in self.quiver.get_incoming(v):\n",
    "                    e_lin = self.matrices[self.edge_tup_to_str(e)]\n",
    "                    h[e[1]] += e_lin(h[e[0]])\n",
    "                if non_linear:\n",
    "                    h[v] = self.act(h[v])\n",
    "        \n",
    "        out = {}\n",
    "        for v in self.quiver.sinks:\n",
    "            out[v] = h[v]\n",
    "            \n",
    "        return out\n",
    "            \n",
    "    \n",
    "    def set_weights(self, new_weights: quiver_rep):\n",
    "        assert new_weights.quiver == self.quiver, \"weights have different quiver\"\n",
    "        \n",
    "        for e in self.quiver.edges:\n",
    "            self.matrices[self.edge_tup_to_str(e)].weight = \\\n",
    "                torch.nn.Parameter(torch.tensor(new_weights.matrices[e],dtype = torch.float))\n",
    "        self.dims = new_weights.dims\n",
    "    \n",
    "    def set_activation_biases(self, new_biases: List[float]):    \n",
    "        None\n",
    "\n",
    "    def export_weights(self) -> quiver_rep:\n",
    "        quiver_rep_matrix_dict = {}\n",
    "        for e in self.quiver.edges:\n",
    "            quiver_rep_matrix_dict[e] = self.matrices[self.edge_tup_to_str(e)].weight.detach().cpu().numpy()\n",
    "        return quiver_rep(self.quiver, self.dims, quiver_rep_matrix_dict)\n",
    "    \n",
    "    def export_activation_biases(self) -> List[float]:\n",
    "        None\n",
    "    \n",
    "    def export_reduced_weights(self) -> quiver_rep:\n",
    "        exported_rep = self.export_weights()\n",
    "        return exported_rep.reduced_representation()\n",
    "    \n",
    "    def transformed_network(self):\n",
    "        exported_rep = self.export_weights()\n",
    "        rep_transformed = exported_rep.transformed_representation()\n",
    "        net_trans = QuiverNN(self.eta, self.quiver, self.dims)\n",
    "        net_trans.set_weights(rep_transformed)\n",
    "        #net_trans.set_activation_biases(self.export_activation_biases())\n",
    "        return net_trans\n",
    "        \n",
    "    def reduced_network(self):\n",
    "        reduced_rep = self.export_reduced_weights()\n",
    "        net_reduced = QuiverNN(self.eta, self.quiver, reduced_rep.dims)\n",
    "        net_reduced.set_weights(reduced_rep)\n",
    "        #net_trans.set_activation_biases(self.export_activation_biases())\n",
    "        return net_reduced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T14:16:49.690028Z",
     "start_time": "2022-03-01T14:16:49.683600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bias': 1, 'a': 1, 'b': 2, 'c': 4, 'd': 2, 'e': 6}\n"
     ]
    }
   ],
   "source": [
    "vertex_list2 = ['a', 'b', 'c', 'd', 'e']\n",
    "edge_list2 = [('a', 'c'), ('b','c'), ('c','d'), ('c', 'e')]\n",
    "dim_vector2 = {'bias' : 1, 'a': 1, 'b': 2, 'c': 8, 'd': 2 , 'e': 6}\n",
    "quiv_ex2 = quiver(vertex_list2, edge_list2)\n",
    "quiv_ex2.add_bias()\n",
    "\n",
    "quiverNN = QuiverNN(eta = F.relu, quiver = quiv_ex2, dims = dim_vector2)\n",
    "\n",
    "# Representation of this quiver\n",
    "\n",
    "maps2 = {('a', 'c') : np.random.rand(8, 1), \n",
    "        ('b', 'c') : np.random.rand(8, 2), \n",
    "        ('c', 'd') : np.random.rand(2, 8),\n",
    "        ('c', 'e') : np.random.rand(6, 8),\n",
    "        ('bias', 'c') : np.random.rand(8, 1),\n",
    "        ('bias', 'd') : np.random.rand(2, 1),\n",
    "        ('bias', 'e') : np.random.rand(6, 1)}\n",
    "\n",
    "ex_rep2 = quiver_rep(quiv_ex2, dim_vector2, maps2)\n",
    "print(ex_rep2.comp_dims_red())\n",
    "\n",
    "quiverNN.set_weights(ex_rep2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T14:16:51.928445Z",
     "start_time": "2022-03-01T14:16:51.923498Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'d': tensor([[4.4020, 6.7395]], grad_fn=<MulBackward0>),\n",
       " 'e': tensor([[7.0381, 7.4217, 6.7195, 3.8931, 5.6222, 5.6682]],\n",
       "        grad_fn=<MulBackward0>)}"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = {'a': torch.tensor([[1.0]]),'b': torch.tensor([[1.0,1.0]])}\n",
    "quiverNN(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T14:16:52.082482Z",
     "start_time": "2022-03-01T14:16:52.077801Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.quiver_rep at 0x7f2efb74c510>"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quiverNN.export_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T14:16:52.226907Z",
     "start_time": "2022-03-01T14:16:52.222142Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.quiver_rep at 0x7f2ef6c12150>"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quiverNN.export_reduced_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T14:16:52.360792Z",
     "start_time": "2022-03-01T14:16:52.357124Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bias': 1, 'a': 1, 'b': 2, 'c': 4, 'd': 2, 'e': 6}"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quiverNN.export_weights().comp_dims_red()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T14:16:52.747249Z",
     "start_time": "2022-03-01T14:16:52.741547Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuiverNN(\n",
       "  (matrices): ModuleDict(\n",
       "    (a to c): Linear(in_features=1, out_features=4, bias=False)\n",
       "    (b to c): Linear(in_features=2, out_features=4, bias=False)\n",
       "    (c to d): Linear(in_features=4, out_features=2, bias=False)\n",
       "    (c to e): Linear(in_features=4, out_features=6, bias=False)\n",
       "    (bias to c): Linear(in_features=1, out_features=4, bias=False)\n",
       "    (bias to d): Linear(in_features=1, out_features=2, bias=False)\n",
       "    (bias to e): Linear(in_features=1, out_features=6, bias=False)\n",
       "  )\n",
       "  (act): RadAct()\n",
       ")"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_quiverNN = quiverNN.reduced_network()\n",
    "red_quiverNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T14:16:54.459367Z",
     "start_time": "2022-03-01T14:16:54.452465Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'d': tensor([[4.4020, 6.7395]], grad_fn=<MulBackward0>),\n",
       " 'e': tensor([[7.0381, 7.4217, 6.7195, 3.8931, 5.6222, 5.6682]],\n",
       "        grad_fn=<MulBackward0>)}"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_quiverNN = quiverNN.reduced_network()\n",
    "x = {'a': torch.tensor([[1.0]]),'b': torch.tensor([[1.0,1.0]])}\n",
    "red_quiverNN(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T14:16:54.861506Z",
     "start_time": "2022-03-01T14:16:54.849848Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bias': 1, 'a': 1, 'b': 2, 'c': 8, 'd': 2, 'e': 6}\n",
      "{'bias': 1, 'a': 1, 'b': 2, 'c': 4, 'd': 2, 'e': 6}\n",
      "\n",
      "('a', 'c')\n",
      "[[-2.03]\n",
      " [ 0.  ]\n",
      " [ 0.  ]\n",
      " [ 0.  ]\n",
      " [ 0.  ]\n",
      " [-0.  ]\n",
      " [-0.  ]\n",
      " [ 0.  ]]\n",
      "\n",
      "('b', 'c')\n",
      "[[-1.77 -2.22]\n",
      " [ 1.19  0.47]\n",
      " [-0.    0.96]\n",
      " [ 0.    0.  ]\n",
      " [-0.   -0.  ]\n",
      " [ 0.    0.  ]\n",
      " [-0.    0.  ]\n",
      " [-0.    0.  ]]\n",
      "\n",
      "('c', 'd')\n",
      "[[-1.23  0.88 -2.15 -1.43  0.34 -0.4  -0.11  0.39]\n",
      " [-1.17  0.63 -2.67 -1.68  0.5  -0.12  0.15  0.3 ]]\n",
      "\n",
      "('c', 'e')\n",
      "[[ 0.93 -0.04  1.12  0.56 -0.65 -0.09  0.68 -0.06]\n",
      " [ 0.99  0.35  1.09  0.55  0.07 -0.28  0.61 -0.32]\n",
      " [ 0.76 -0.31  0.36  0.34 -0.77 -0.45  0.3  -0.8 ]\n",
      " [ 0.99  0.3   1.13  0.79 -0.64 -0.46  0.29 -0.45]\n",
      " [ 0.92 -0.49  0.96  0.65 -1.02 -0.84  0.23 -0.57]\n",
      " [ 1.19  0.02  1.4   0.35 -0.54 -0.64  0.14 -0.63]]\n",
      "\n",
      "('bias', 'c')\n",
      "[[-1.4 ]\n",
      " [ 1.02]\n",
      " [-0.49]\n",
      " [-0.9 ]\n",
      " [ 0.  ]\n",
      " [ 0.  ]\n",
      " [-0.  ]\n",
      " [ 0.  ]]\n",
      "\n",
      "('bias', 'd')\n",
      "[[0.79]\n",
      " [0.07]]\n",
      "\n",
      "('bias', 'e')\n",
      "[[0.7 ]\n",
      " [0.72]\n",
      " [0.69]\n",
      " [0.8 ]\n",
      " [0.02]\n",
      " [0.72]]\n"
     ]
    }
   ],
   "source": [
    "print(quiverNN.dims)\n",
    "print(quiverNN.export_reduced_weights().dims)\n",
    "for e in T.quiver.edges:\n",
    "    print()\n",
    "    print(e)\n",
    "    print(T.get_matrix(e).detach().cpu().numpy().round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Theorem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T14:16:59.342054Z",
     "start_time": "2022-03-01T14:16:59.334996Z"
    }
   },
   "outputs": [],
   "source": [
    "W = quiverNN.export_weights()\n",
    "T = quiverNN.transformed_network()\n",
    "Q,V = quiverNN.export_weights().QRDimRed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_mask(red_rows, red_cols, orig_rows, orig_cols):\n",
    "    assert red_rows <= orig_rows \n",
    "    assert red_cols <= orig_cols\n",
    "    mask = torch.ones((orig_rows, orig_cols))\n",
    "    for j in range(red_rows, orig_rows):\n",
    "        mask[j][:red_cols] = 0\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T14:26:13.596195Z",
     "start_time": "2022-03-01T14:26:13.584820Z"
    }
   },
   "outputs": [],
   "source": [
    "def gamma(model, x, lr):\n",
    "    \n",
    "    y = model(x)\n",
    "    \n",
    "    L = torch.tensor(0.0)\n",
    "    for k in y:\n",
    "        L += y[k].pow(2).mean()\n",
    "    L.backward()\n",
    "    \n",
    "    with torch.no_grad(): \n",
    "        for e in model.quiver.edges:\n",
    "            p = model.get_matrix(e)\n",
    "            p -= lr * p.grad\n",
    "    \n",
    "    print(L)\n",
    "    \n",
    "    return model\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T14:28:09.212344Z",
     "start_time": "2022-03-01T14:28:09.196272Z"
    }
   },
   "outputs": [],
   "source": [
    "def gammaPGD(model, x, lr):\n",
    "    \n",
    "    y = model(x)\n",
    "    \n",
    "    dims = model.dims \n",
    "    red_dims = model.export_reduced_weights().dims\n",
    "    \n",
    "    L = torch.tensor(0.0)\n",
    "    for k in y:\n",
    "        L += y[k].pow(2).mean()\n",
    "    L.backward()\n",
    "    \n",
    "    with torch.no_grad(): \n",
    "        for e in model.quiver.edges:\n",
    "            p = model.get_matrix(e)\n",
    "            mask_grad = single_mask(red_dims[e[1]],red_dims[e[0]],dims[e[1]],dims[e[0]])\n",
    "            p -= lr * (mask_grad * p.grad)\n",
    "    \n",
    "    print(L)\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T14:28:10.563074Z",
     "start_time": "2022-03-01T14:28:10.558253Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3496, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "x = {'a': torch.tensor([[1.0]]),'b': torch.tensor([[1.0,1.0]])}\n",
    "\n",
    "gamma(quiverNN, x, lr);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T14:28:20.423436Z",
     "start_time": "2022-03-01T14:28:20.413352Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bias': 1, 'a': 1, 'b': 2, 'c': 4, 'd': 2, 'e': 6}\n",
      "{'bias': 1, 'a': 1, 'b': 2, 'c': 4, 'd': 2, 'e': 6}\n",
      "{'bias': 1, 'a': 1, 'b': 2, 'c': 4, 'd': 2, 'e': 6}\n",
      "{'bias': 1, 'a': 1, 'b': 2, 'c': 4, 'd': 2, 'e': 6}\n",
      "{'bias': 1, 'a': 1, 'b': 2, 'c': 4, 'd': 2, 'e': 6}\n",
      "{'bias': 1, 'a': 1, 'b': 2, 'c': 4, 'd': 2, 'e': 6}\n",
      "{'bias': 1, 'a': 1, 'b': 2, 'c': 4, 'd': 2, 'e': 6}\n",
      "tensor(7.5227, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "x = {'a': torch.tensor([[1.0]]),'b': torch.tensor([[1.0,1.0]])}\n",
    "\n",
    "gammaPGD(quiverNN, x, lr);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T04:28:14.191343Z",
     "start_time": "2022-03-01T04:28:14.162307Z"
    }
   },
   "outputs": [],
   "source": [
    "#################################\n",
    "## Loss function (mean square error)\n",
    "#################################\n",
    "\n",
    "def loss_fn(y_predict, y_train):\n",
    "    squared_diffs = (y_predict - y_train)**2\n",
    "    return squared_diffs.mean()\n",
    "\n",
    "\n",
    "#################################\n",
    "## Masks used in projected gradient descent\n",
    "#################################\n",
    "\n",
    "def single_mask(red_rows, red_cols, orig_rows, orig_cols):\n",
    "    assert red_rows <= orig_rows \n",
    "    assert red_cols <= orig_cols\n",
    "    mask = torch.ones((orig_rows, orig_cols))\n",
    "    for j in range(red_rows, orig_rows):\n",
    "        mask[j][:red_cols] = 0\n",
    "    return mask\n",
    "\n",
    "def masks(reduced_dims, orig_dims):\n",
    "    N = len(reduced_dims)\n",
    "    assert N == len(orig_dims), \\\n",
    "    \"Lengths must match\"\n",
    "    assert all([reduced_dims[i] <= orig_dims[i] for i in range(N)]), \\\n",
    "        \"Reduced dimension vector must not be larger in any coordinate\"\n",
    "    \n",
    "    masks = []\n",
    "    \n",
    "    # Add masks in order corresponding to the parameters\n",
    "    for i in range(N-1):\n",
    "        masks.append(single_mask(reduced_dims[i+1], reduced_dims[i], orig_dims[i+1], orig_dims[i]))\n",
    "        masks.append(torch.transpose(single_mask(reduced_dims[i+1], 1, orig_dims[i+1],1 ), 0,1).reshape(orig_dims[i+1]))\n",
    "    \n",
    "    return(masks)\n",
    "\n",
    "\n",
    "#################################\n",
    "## Training loop with usual gradient descent\n",
    "## Optimizer excluded to remove randomness\n",
    "#################################\n",
    "\n",
    "def training_loop(n_epochs, learning_rate, model, params, x_train, y_train, verbose=True):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        for p in params:\n",
    " \n",
    "          if p.grad is not None: \n",
    "                p.grad.zero_()\n",
    "        \n",
    "        y_pred = model(x_train) \n",
    "        loss = loss_fn(y_pred, y_train)            \n",
    "        loss.backward()\n",
    "        \n",
    "        with torch.no_grad(): \n",
    "            for p in params:\n",
    "                p -= learning_rate * p.grad\n",
    "                \n",
    "        if verbose:\n",
    "            if epoch ==1 or epoch % 500 == 0:\n",
    "                print('Epoch %d, Loss %f' % (epoch, float(loss)))\n",
    "            \n",
    "    return model\n",
    "\n",
    "\n",
    "#################################\n",
    "## Training loop with projected gradient descent\n",
    "## Optimizer excluded to remove randomness\n",
    "#################################\n",
    "\n",
    "def training_loop_proj_GD(n_epochs, learning_rate, model, params, original_dimensions, reduced_dimensions, \\\n",
    "                          x_train, y_train, verbose=True):\n",
    "    \n",
    "    param_masks = masks(reduced_dimensions, original_dimensions)\n",
    "    \n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        for p in params:\n",
    "            if p.grad is not None: \n",
    "                p.grad.zero_()\n",
    "        \n",
    "        y_pred = model(x_train) \n",
    "        loss = loss_fn(y_pred, y_train)            \n",
    "        loss.backward()\n",
    "        \n",
    "        with torch.no_grad(): \n",
    "            for p,m in zip(params, param_masks):\n",
    "                assert p.shape == m.shape, \"Parameter shape and mask shape don't match\"\n",
    "                \n",
    "                # Use the mask to zero out gradients that will not be updated\n",
    "                p -= learning_rate * (p.grad * m)\n",
    "                \n",
    "        if verbose:\n",
    "            if epoch ==1 or epoch % 500 == 0:\n",
    "                print('Epoch %d, Loss %f' % (epoch, float(loss)))\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T19:15:45.683291Z",
     "start_time": "2022-02-18T19:15:44.729Z"
    }
   },
   "outputs": [],
   "source": [
    "class vertex:\n",
    "    def __init__(self):\n",
    "        None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T19:15:45.683918Z",
     "start_time": "2022-02-18T19:15:44.730Z"
    }
   },
   "outputs": [],
   "source": [
    "a = vertex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T19:15:45.684576Z",
     "start_time": "2022-02-18T19:15:44.734Z"
    }
   },
   "outputs": [],
   "source": [
    "# Troubleshooting\n",
    "\n",
    "W1 = np.random.rand(4, 2)\n",
    "print(type(W1))\n",
    "print(isinstance(W1, np.ndarray))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T19:15:45.685171Z",
     "start_time": "2022-02-18T19:15:44.737Z"
    }
   },
   "outputs": [],
   "source": [
    "a = np.random.rand(4,2)\n",
    "b = np.random.rand(4,4)\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T19:15:45.685709Z",
     "start_time": "2022-02-18T19:15:44.737Z"
    }
   },
   "outputs": [],
   "source": [
    "c = np.hstack((a,b))\n",
    "np.shape(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T19:15:45.686275Z",
     "start_time": "2022-02-18T19:15:44.739Z"
    }
   },
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T19:15:45.686990Z",
     "start_time": "2022-02-18T19:15:44.740Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "b[:,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T19:15:45.687633Z",
     "start_time": "2022-02-18T19:15:44.741Z"
    }
   },
   "outputs": [],
   "source": [
    "b[:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T19:15:45.688326Z",
     "start_time": "2022-02-18T19:15:44.743Z"
    }
   },
   "outputs": [],
   "source": [
    "np.shape(b[:,:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T19:15:45.689007Z",
     "start_time": "2022-02-18T19:15:44.744Z"
    }
   },
   "outputs": [],
   "source": [
    "np.shape(np.array([]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T12:58:12.661152Z",
     "start_time": "2022-03-01T12:58:12.642219Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tensor() got an unexpected keyword argument 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-186-af1b9ec111c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"a to b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: tensor() got an unexpected keyword argument 'name'"
     ]
    }
   ],
   "source": [
    "torch.nn.Parameter(torch.tensor([[1.0]],dtype = torch.float,name=\"a to b\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
